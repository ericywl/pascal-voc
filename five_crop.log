Epoch 0
======================
TRAIN:
[0/5717 (0%)] Loss: 0.387676
[1600/5717 (28%)] Loss: 0.110575
[3200/5717 (56%)] Loss: 0.083923
[4800/5717 (84%)] Loss: 0.085774
[5717/5717 (100%)] Loss: 0.073063
Average training loss: 0.11039109266512877
VAL:
[0/5823 (0%)] Loss: 0.063492
[1600/5823 (27%)] Loss: 0.105180
[3200/5823 (55%)] Loss: 0.095148
[4800/5823 (82%)] Loss: 0.075705
[5823/5823 (100%)] Loss: 0.119373
Average validation loss: 0.0883558522756365
AP: 0.2663071932209174
Accuracy: 0.02370973490178585

Epoch 1
======================
TRAIN:
[0/5717 (0%)] Loss: 0.096431
[1600/5717 (28%)] Loss: 0.098371
[3200/5717 (56%)] Loss: 0.070295
[4800/5717 (84%)] Loss: 0.079856
[5717/5717 (100%)] Loss: 0.097333
Average training loss: 0.08741514037226464
VAL:
[0/5823 (0%)] Loss: 0.068590
[1600/5823 (27%)] Loss: 0.051102
[3200/5823 (55%)] Loss: 0.061009
[4800/5823 (82%)] Loss: 0.083916
[5823/5823 (100%)] Loss: 0.096319
Average validation loss: 0.07705763773992658
AP: 0.47681611923581874
Accuracy: 0.033648665994405746

Epoch 2
======================
TRAIN:
[0/5717 (0%)] Loss: 0.087675
[1600/5717 (28%)] Loss: 0.072201
[3200/5717 (56%)] Loss: 0.086241
[4800/5717 (84%)] Loss: 0.070723
[5717/5717 (100%)] Loss: 0.055394
Average training loss: 0.07835072657236686
VAL:
[0/5823 (0%)] Loss: 0.093142
[1600/5823 (27%)] Loss: 0.075438
[3200/5823 (55%)] Loss: 0.068182
[4800/5823 (82%)] Loss: 0.077746
[5823/5823 (100%)] Loss: 0.065974
Average validation loss: 0.06778465760974112
AP: 0.579527704304631
Accuracy: 0.1016644686460495

Epoch 3
======================
TRAIN:
[0/5717 (0%)] Loss: 0.061602
[1600/5717 (28%)] Loss: 0.086296
[3200/5717 (56%)] Loss: 0.075562
[4800/5717 (84%)] Loss: 0.095904
[5717/5717 (100%)] Loss: 0.051621
Average training loss: 0.07132101048539569
VAL:
[0/5823 (0%)] Loss: 0.050592
[1600/5823 (27%)] Loss: 0.065981
[3200/5823 (55%)] Loss: 0.057509
[4800/5823 (82%)] Loss: 0.067055
[5823/5823 (100%)] Loss: 0.058614
Average validation loss: 0.06061171691168796
AP: 0.6247587104201825
Accuracy: 0.23613938689231873

Epoch 4
======================
TRAIN:
[0/5717 (0%)] Loss: 0.077979
[1600/5717 (28%)] Loss: 0.064902
[3200/5717 (56%)] Loss: 0.071177
[4800/5717 (84%)] Loss: 0.051069
[5717/5717 (100%)] Loss: 0.052117
Average training loss: 0.06604437336742461
VAL:
[0/5823 (0%)] Loss: 0.046338
[1600/5823 (27%)] Loss: 0.040966
[3200/5823 (55%)] Loss: 0.059262
[4800/5823 (82%)] Loss: 0.049640
[5823/5823 (100%)] Loss: 0.045243
Average validation loss: 0.05621246108529414
AP: 0.6550502244333133
Accuracy: 0.3443898856639862

Epoch 5
======================
TRAIN:
[0/5717 (0%)] Loss: 0.087858
[1600/5717 (28%)] Loss: 0.064796
[3200/5717 (56%)] Loss: 0.051356
[4800/5717 (84%)] Loss: 0.058948
[5717/5717 (100%)] Loss: 0.072510
Average training loss: 0.061674220328564414
VAL:
[0/5823 (0%)] Loss: 0.036057
[1600/5823 (27%)] Loss: 0.039714
[3200/5823 (55%)] Loss: 0.029424
[4800/5823 (82%)] Loss: 0.075973
[5823/5823 (100%)] Loss: 0.056273
Average validation loss: 0.052504762096310054
AP: 0.6757547168209732
Accuracy: 0.42126691341400146

Epoch 6
======================
TRAIN:
[0/5717 (0%)] Loss: 0.054013
[1600/5717 (28%)] Loss: 0.059052
[3200/5717 (56%)] Loss: 0.081156
[4800/5717 (84%)] Loss: 0.043082
[5717/5717 (100%)] Loss: 0.072699
Average training loss: 0.0586791159259481
VAL:
[0/5823 (0%)] Loss: 0.053072
[1600/5823 (27%)] Loss: 0.047318
[3200/5823 (55%)] Loss: 0.048844
[4800/5823 (82%)] Loss: 0.055142
[5823/5823 (100%)] Loss: 0.031248
Average validation loss: 0.049739162028245215
AP: 0.6952634684707851
Accuracy: 0.48509159684181213

Epoch 7
======================
TRAIN:
[0/5717 (0%)] Loss: 0.041533
[1600/5717 (28%)] Loss: 0.048440
[3200/5717 (56%)] Loss: 0.034051
[4800/5717 (84%)] Loss: 0.048972
[5717/5717 (100%)] Loss: 0.046771
Average training loss: 0.05594616417440918
VAL:
[0/5823 (0%)] Loss: 0.048149
[1600/5823 (27%)] Loss: 0.037520
[3200/5823 (55%)] Loss: 0.064785
[4800/5823 (82%)] Loss: 0.058978
[5823/5823 (100%)] Loss: 0.038511
Average validation loss: 0.047450784453098756
AP: 0.7116019580526731
Accuracy: 0.5096395611763

Epoch 8
======================
TRAIN:
[0/5717 (0%)] Loss: 0.055090
[1600/5717 (28%)] Loss: 0.052970
[3200/5717 (56%)] Loss: 0.084520
[4800/5717 (84%)] Loss: 0.039178
[5717/5717 (100%)] Loss: 0.049489
Average training loss: 0.05361768381370531
VAL:
[0/5823 (0%)] Loss: 0.056122
[1600/5823 (27%)] Loss: 0.049582
[3200/5823 (55%)] Loss: 0.032366
[4800/5823 (82%)] Loss: 0.091417
[5823/5823 (100%)] Loss: 0.037316
Average validation loss: 0.04607807188090142
AP: 0.7264852166100527
Accuracy: 0.5607711672782898

Epoch 9
======================
TRAIN:
[0/5717 (0%)] Loss: 0.038695
[1600/5717 (28%)] Loss: 0.049813
[3200/5717 (56%)] Loss: 0.050497
[4800/5717 (84%)] Loss: 0.036769
[5717/5717 (100%)] Loss: 0.081575
Average training loss: 0.051789392736720875
VAL:
[0/5823 (0%)] Loss: 0.053701
[1600/5823 (27%)] Loss: 0.057918
[3200/5823 (55%)] Loss: 0.045291
[4800/5823 (82%)] Loss: 0.021648
[5823/5823 (100%)] Loss: 0.042617
Average validation loss: 0.04393678720641349
AP: 0.7398200430794886
Accuracy: 0.5652017593383789

Epoch 10
======================
TRAIN:
[0/5717 (0%)] Loss: 0.051099
[1600/5717 (28%)] Loss: 0.069069
[3200/5717 (56%)] Loss: 0.093822
[4800/5717 (84%)] Loss: 0.056161
[5717/5717 (100%)] Loss: 0.090073
Average training loss: 0.050138935561363514
VAL:
[0/5823 (0%)] Loss: 0.044332
[1600/5823 (27%)] Loss: 0.049296
[3200/5823 (55%)] Loss: 0.038165
[4800/5823 (82%)] Loss: 0.031307
[5823/5823 (100%)] Loss: 0.027827
Average validation loss: 0.042573924969554276
AP: 0.750600289580081
Accuracy: 0.586995542049408

Epoch 11
======================
TRAIN:
[0/5717 (0%)] Loss: 0.031850
[1600/5717 (28%)] Loss: 0.043568
[3200/5717 (56%)] Loss: 0.042881
[4800/5717 (84%)] Loss: 0.045779
[5717/5717 (100%)] Loss: 0.056388
Average training loss: 0.04858380961980853
VAL:
[0/5823 (0%)] Loss: 0.051498
[1600/5823 (27%)] Loss: 0.027170
[3200/5823 (55%)] Loss: 0.038406
[4800/5823 (82%)] Loss: 0.033369
[5823/5823 (100%)] Loss: 0.051183
Average validation loss: 0.04166345379653049
AP: 0.7600170326402923
Accuracy: 0.5848401188850403

Epoch 12
======================
TRAIN:
[0/5717 (0%)] Loss: 0.047746
[1600/5717 (28%)] Loss: 0.048310
[3200/5717 (56%)] Loss: 0.037367
[4800/5717 (84%)] Loss: 0.031998
[5717/5717 (100%)] Loss: 0.032832
Average training loss: 0.047264918869921374
VAL:
[0/5823 (0%)] Loss: 0.052344
[1600/5823 (27%)] Loss: 0.047049
[3200/5823 (55%)] Loss: 0.038654
[4800/5823 (82%)] Loss: 0.049157
[5823/5823 (100%)] Loss: 0.065001
Average validation loss: 0.040854047873865935
AP: 0.7692036503130912
Accuracy: 0.6326188445091248

Epoch 13
======================
TRAIN:
[0/5717 (0%)] Loss: 0.047759
[1600/5717 (28%)] Loss: 0.029778
[3200/5717 (56%)] Loss: 0.035480
[4800/5717 (84%)] Loss: 0.045074
[5717/5717 (100%)] Loss: 0.052116
Average training loss: 0.045715612162660055
VAL:
[0/5823 (0%)] Loss: 0.027544
[1600/5823 (27%)] Loss: 0.061070
[3200/5823 (55%)] Loss: 0.040674
[4800/5823 (82%)] Loss: 0.049004
[5823/5823 (100%)] Loss: 0.040363
Average validation loss: 0.039446230396976346
AP: 0.7767295683776579
Accuracy: 0.6305831670761108

Epoch 14
======================
TRAIN:
[0/5717 (0%)] Loss: 0.091146
[1600/5717 (28%)] Loss: 0.031027
[3200/5717 (56%)] Loss: 0.051861
[4800/5717 (84%)] Loss: 0.020885
[5717/5717 (100%)] Loss: 0.021601
Average training loss: 0.045012301568697385
VAL:
[0/5823 (0%)] Loss: 0.016895
[1600/5823 (27%)] Loss: 0.038436
[3200/5823 (55%)] Loss: 0.040629
[4800/5823 (82%)] Loss: 0.042807
[5823/5823 (100%)] Loss: 0.067177
Average validation loss: 0.03868879841584303
AP: 0.7826255851597275
Accuracy: 0.6521374583244324

Epoch 15
======================
TRAIN:
[0/5717 (0%)] Loss: 0.035880
[1600/5717 (28%)] Loss: 0.041030
[3200/5717 (56%)] Loss: 0.021998
[4800/5717 (84%)] Loss: 0.044811
[5717/5717 (100%)] Loss: 0.049031
Average training loss: 0.04376593880563766
VAL:
[0/5823 (0%)] Loss: 0.062692
[1600/5823 (27%)] Loss: 0.041257
[3200/5823 (55%)] Loss: 0.058260
[4800/5823 (82%)] Loss: 0.041371
[5823/5823 (100%)] Loss: 0.057360
Average validation loss: 0.03869462815358989
AP: 0.7874064720984931
Accuracy: 0.6481858491897583

Epoch 16
======================
TRAIN:
[0/5717 (0%)] Loss: 0.045108
[1600/5717 (28%)] Loss: 0.032274
[3200/5717 (56%)] Loss: 0.040748
[4800/5717 (84%)] Loss: 0.027478
[5717/5717 (100%)] Loss: 0.070432
Average training loss: 0.04288591143603508
VAL:
[0/5823 (0%)] Loss: 0.027328
[1600/5823 (27%)] Loss: 0.048287
[3200/5823 (55%)] Loss: 0.034258
[4800/5823 (82%)] Loss: 0.027140
[5823/5823 (100%)] Loss: 0.047620
Average validation loss: 0.037447681598068515
AP: 0.7920950362341095
Accuracy: 0.6518979668617249

Epoch 17
======================
TRAIN:
[0/5717 (0%)] Loss: 0.036598
[1600/5717 (28%)] Loss: 0.048267
[3200/5717 (56%)] Loss: 0.035522
[4800/5717 (84%)] Loss: 0.051300
[5717/5717 (100%)] Loss: 0.049710
Average training loss: 0.041852300012340915
VAL:
[0/5823 (0%)] Loss: 0.045205
[1600/5823 (27%)] Loss: 0.023084
[3200/5823 (55%)] Loss: 0.034858
[4800/5823 (82%)] Loss: 0.020842
[5823/5823 (100%)] Loss: 0.013239
Average validation loss: 0.03689073555294301
AP: 0.7957889343477194
Accuracy: 0.6709375977516174

Epoch 18
======================
TRAIN:
[0/5717 (0%)] Loss: 0.056285
[1600/5717 (28%)] Loss: 0.021871
[3200/5717 (56%)] Loss: 0.021054
[4800/5717 (84%)] Loss: 0.053337
[5717/5717 (100%)] Loss: 0.035318
Average training loss: 0.0408622267714643
VAL:
[0/5823 (0%)] Loss: 0.033161
[1600/5823 (27%)] Loss: 0.042630
[3200/5823 (55%)] Loss: 0.032171
[4800/5823 (82%)] Loss: 0.035142
[5823/5823 (100%)] Loss: 0.025698
Average validation loss: 0.036773272032675504
AP: 0.801395889903857
Accuracy: 0.6892587542533875

Epoch 19
======================
TRAIN:
[0/5717 (0%)] Loss: 0.028013
[1600/5717 (28%)] Loss: 0.064112
[3200/5717 (56%)] Loss: 0.031354
[4800/5717 (84%)] Loss: 0.028975
[5717/5717 (100%)] Loss: 0.045500
Average training loss: 0.04022795630918516
VAL:
[0/5823 (0%)] Loss: 0.031440
[1600/5823 (27%)] Loss: 0.064980
[3200/5823 (55%)] Loss: 0.044293
[4800/5823 (82%)] Loss: 0.029501
[5823/5823 (100%)] Loss: 0.052209
Average validation loss: 0.036336697693044255
AP: 0.804817632823854
Accuracy: 0.6851873993873596

Epoch 20
======================
TRAIN:
[0/5717 (0%)] Loss: 0.030824
[1600/5717 (28%)] Loss: 0.037929
[3200/5717 (56%)] Loss: 0.032487
[4800/5717 (84%)] Loss: 0.038337
[5717/5717 (100%)] Loss: 0.031099
Average training loss: 0.03951060407358658
VAL:
[0/5823 (0%)] Loss: 0.068051
[1600/5823 (27%)] Loss: 0.040216
[3200/5823 (55%)] Loss: 0.037510
[4800/5823 (82%)] Loss: 0.027297
[5823/5823 (100%)] Loss: 0.033411
Average validation loss: 0.036132751779175354
AP: 0.8080949058042949
Accuracy: 0.711172342300415

Epoch 21
======================
TRAIN:
[0/5717 (0%)] Loss: 0.034915
[1600/5717 (28%)] Loss: 0.068997
[3200/5717 (56%)] Loss: 0.032520
[4800/5717 (84%)] Loss: 0.046439
[5717/5717 (100%)] Loss: 0.032998
Average training loss: 0.03877454591928037
VAL:
[0/5823 (0%)] Loss: 0.017947
[1600/5823 (27%)] Loss: 0.047572
[3200/5823 (55%)] Loss: 0.034474
[4800/5823 (82%)] Loss: 0.031512
[5823/5823 (100%)] Loss: 0.036696
Average validation loss: 0.03476591140305582
AP: 0.8106558485534116
Accuracy: 0.6885402798652649

Epoch 22
======================
TRAIN:
[0/5717 (0%)] Loss: 0.046774
[1600/5717 (28%)] Loss: 0.024143
[3200/5717 (56%)] Loss: 0.021206
[4800/5717 (84%)] Loss: 0.031534
[5717/5717 (100%)] Loss: 0.049939
Average training loss: 0.03836698688149869
VAL:
[0/5823 (0%)] Loss: 0.040269
[1600/5823 (27%)] Loss: 0.017498
[3200/5823 (55%)] Loss: 0.029328
[4800/5823 (82%)] Loss: 0.022817
[5823/5823 (100%)] Loss: 0.012307
Average validation loss: 0.03502878346761873
AP: 0.8135669515285141
Accuracy: 0.7117710709571838

Epoch 23
======================
TRAIN:
[0/5717 (0%)] Loss: 0.060674
[1600/5717 (28%)] Loss: 0.068831
[3200/5717 (56%)] Loss: 0.031757
[4800/5717 (84%)] Loss: 0.040048
[5717/5717 (100%)] Loss: 0.033655
Average training loss: 0.037813899602246036
VAL:
[0/5823 (0%)] Loss: 0.019818
[1600/5823 (27%)] Loss: 0.020554
[3200/5823 (55%)] Loss: 0.039357
[4800/5823 (82%)] Loss: 0.019572
[5823/5823 (100%)] Loss: 0.032056
Average validation loss: 0.03494831791101535
AP: 0.8153619676600673
Accuracy: 0.7209914922714233

Epoch 24
======================
TRAIN:
[0/5717 (0%)] Loss: 0.025360
[1600/5717 (28%)] Loss: 0.040036
[3200/5717 (56%)] Loss: 0.029487
[4800/5717 (84%)] Loss: 0.040175
[5717/5717 (100%)] Loss: 0.031826
Average training loss: 0.03702148583333392
VAL:
[0/5823 (0%)] Loss: 0.030562
[1600/5823 (27%)] Loss: 0.041813
[3200/5823 (55%)] Loss: 0.032780
[4800/5823 (82%)] Loss: 0.029720
[5823/5823 (100%)] Loss: 0.031922
Average validation loss: 0.03435632153119953
AP: 0.8185841691482232
Accuracy: 0.7096155881881714

Epoch 25
======================
TRAIN:
[0/5717 (0%)] Loss: 0.038762
[1600/5717 (28%)] Loss: 0.029007
[3200/5717 (56%)] Loss: 0.047983
[4800/5717 (84%)] Loss: 0.025646
[5717/5717 (100%)] Loss: 0.038435
Average training loss: 0.03669632187933772
VAL:
[0/5823 (0%)] Loss: 0.049057
[1600/5823 (27%)] Loss: 0.032717
[3200/5823 (55%)] Loss: 0.030670
[4800/5823 (82%)] Loss: 0.023337
[5823/5823 (100%)] Loss: 0.068920
Average validation loss: 0.03479240904690104
AP: 0.8205932404848862
Accuracy: 0.7317686676979065

Epoch 26
======================
TRAIN:
[0/5717 (0%)] Loss: 0.035528
[1600/5717 (28%)] Loss: 0.028245
[3200/5717 (56%)] Loss: 0.036509
[4800/5717 (84%)] Loss: 0.033700
[5717/5717 (100%)] Loss: 0.072039
Average training loss: 0.03550594145419089
VAL:
[0/5823 (0%)] Loss: 0.022229
[1600/5823 (27%)] Loss: 0.040842
[3200/5823 (55%)] Loss: 0.035165
[4800/5823 (82%)] Loss: 0.020852
[5823/5823 (100%)] Loss: 0.043125
Average validation loss: 0.033679147986541653
AP: 0.8212854667379139
Accuracy: 0.7042270302772522

Epoch 27
======================
TRAIN:
[0/5717 (0%)] Loss: 0.037147
[1600/5717 (28%)] Loss: 0.030438
[3200/5717 (56%)] Loss: 0.067721
[4800/5717 (84%)] Loss: 0.039583
[5717/5717 (100%)] Loss: 0.060262
Average training loss: 0.03522987956168143
VAL:
[0/5823 (0%)] Loss: 0.024460
[1600/5823 (27%)] Loss: 0.012713
[3200/5823 (55%)] Loss: 0.022417
[4800/5823 (82%)] Loss: 0.031135
[5823/5823 (100%)] Loss: 0.061295
Average validation loss: 0.03341143530061735
AP: 0.8250392942455781
Accuracy: 0.7081786394119263

Epoch 28
======================
TRAIN:
[0/5717 (0%)] Loss: 0.032203
[1600/5717 (28%)] Loss: 0.054363
[3200/5717 (56%)] Loss: 0.026001
[4800/5717 (84%)] Loss: 0.033281
[5717/5717 (100%)] Loss: 0.026270
Average training loss: 0.03484660684150624
VAL:
[0/5823 (0%)] Loss: 0.020131
[1600/5823 (27%)] Loss: 0.039863
[3200/5823 (55%)] Loss: 0.030792
[4800/5823 (82%)] Loss: 0.023442
[5823/5823 (100%)] Loss: 0.062459
Average validation loss: 0.03333446566862371
AP: 0.8261920829411974
Accuracy: 0.7263800501823425

Epoch 29
======================
TRAIN:
[0/5717 (0%)] Loss: 0.026922
[1600/5717 (28%)] Loss: 0.028363
[3200/5717 (56%)] Loss: 0.036494
[4800/5717 (84%)] Loss: 0.026676
[5717/5717 (100%)] Loss: 0.055874
Average training loss: 0.03411711946755022
VAL:
[0/5823 (0%)] Loss: 0.055518
[1600/5823 (27%)] Loss: 0.016145
[3200/5823 (55%)] Loss: 0.033445
[4800/5823 (82%)] Loss: 0.051288
[5823/5823 (100%)] Loss: 0.033092
Average validation loss: 0.033324900813078366
AP: 0.8279982562051739
Accuracy: 0.7326068878173828
{tensor(0.5000, device='cuda:0'): tensor([0.9652, 0.8115, 0.9591, 0.8710, 0.6752, 0.9572, 0.8276, 0.9240, 0.6674,
        0.7143, 0.5854, 0.8934, 0.7778, 0.8118, 0.9291, 0.6105, 0.7348, 0.6348,
        0.9510, 0.8879], device='cuda:0'),
 tensor(0.5250, device='cuda:0'): tensor([0.9683, 0.8164, 0.9643, 0.8821, 0.6930, 0.9676, 0.8385, 0.9325, 0.6790,
        0.7305, 0.6007, 0.9018, 0.7878, 0.8178, 0.9387, 0.6159, 0.7644, 0.6530,
        0.9506, 0.8995], device='cuda:0'),
 tensor(0.5500, device='cuda:0'): tensor([0.9710, 0.8340, 0.9726, 0.8841, 0.6995, 0.9724, 0.8595, 0.9431, 0.7040,
        0.7353, 0.6275, 0.9154, 0.7950, 0.8257, 0.9475, 0.6471, 0.7719, 0.6682,
        0.9583, 0.9159], device='cuda:0'),
 tensor(0.5750, device='cuda:0'): tensor([0.9740, 0.8443, 0.9816, 0.8841, 0.7181, 0.9777, 0.8663, 0.9486, 0.7191,
        0.7388, 0.6485, 0.9189, 0.8026, 0.8354, 0.9589, 0.6575, 0.7811, 0.6800,
        0.9620, 0.9194], device='cuda:0'),
 tensor(0.6000, device='cuda:0'): tensor([0.9737, 0.8458, 0.9816, 0.8878, 0.7348, 0.9775, 0.8856, 0.9562, 0.7297,
        0.7402, 0.6652, 0.9266, 0.8122, 0.8448, 0.9654, 0.6947, 0.7904, 0.6947,
        0.9658, 0.9279], device='cuda:0'),
 tensor(0.6250, device='cuda:0'): tensor([0.9765, 0.8596, 0.9815, 0.9050, 0.7543, 0.9830, 0.8933, 0.9601, 0.7346,
        0.7797, 0.6743, 0.9382, 0.8097, 0.8515, 0.9752, 0.7040, 0.8137, 0.6940,
        0.9655, 0.9363], device='cuda:0'),
 tensor(0.6500, device='cuda:0'): tensor([0.9763, 0.8795, 0.9813, 0.9026, 0.7879, 0.9829, 0.9038, 0.9637, 0.7478,
        0.7826, 0.6777, 0.9409, 0.8186, 0.8649, 0.9806, 0.7119, 0.8387, 0.7018,
        0.9696, 0.9397], device='cuda:0'),
 tensor(0.6750, device='cuda:0'): tensor([0.9828, 0.8894, 0.9841, 0.9110, 0.8117, 0.9827, 0.9288, 0.9739, 0.7437,
        0.8036, 0.6919, 0.9414, 0.8221, 0.8688, 0.9873, 0.7222, 0.8442, 0.7083,
        0.9738, 0.9442], device='cuda:0'),
 tensor(0.7000, device='cuda:0'): tensor([0.9826, 0.9043, 0.9935, 0.9293, 0.8451, 0.9825, 0.9393, 0.9737, 0.7517,
        0.8447, 0.6947, 0.9460, 0.8325, 0.8716, 0.9891, 0.7576, 0.8487, 0.7239,
        0.9821, 0.9433], device='cuda:0'),
 tensor(0.7250, device='cuda:0'): tensor([0.9860, 0.9208, 0.9935, 0.9392, 0.8489, 0.9821, 0.9517, 0.9823, 0.7606,
        0.8500, 0.7127, 0.9490, 0.8497, 0.8826, 0.9894, 0.7667, 0.8571, 0.7635,
        0.9864, 0.9465], device='cuda:0'),
 tensor(0.7500, device='cuda:0'): tensor([0.9857, 0.9286, 0.9934, 0.9438, 0.8409, 0.9816, 0.9608, 0.9821, 0.7790,
        0.8469, 0.7246, 0.9497, 0.8587, 0.8981, 0.9914, 0.7848, 0.8621, 0.7857,
        0.9862, 0.9462], device='cuda:0'),
 tensor(0.7750, device='cuda:0'): tensor([0.9855, 0.9372, 0.9934, 0.9425, 0.8430, 0.9875, 0.9786, 0.9841, 0.7843,
        0.8696, 0.7582, 0.9564, 0.8588, 0.9015, 0.9935, 0.7941, 0.8723, 0.7910,
        0.9861, 0.9497], device='cuda:0'),
 tensor(0.8000, device='cuda:0'): tensor([0.9889, 0.9415, 0.9933, 0.9415, 0.8468, 0.9875, 0.9860, 0.9861, 0.7931,
        0.8929, 0.7500, 0.9647, 0.8555, 0.9231, 0.9960, 0.8475, 0.8741, 0.7869,
        0.9858, 0.9602], device='cuda:0'),
 tensor(0.8250, device='cuda:0'): tensor([0.9888, 0.9454, 0.9932, 0.9455, 0.8725, 0.9936, 0.9855, 0.9904, 0.8075,
        0.9189, 0.7891, 0.9736, 0.8512, 0.9521, 0.9967, 0.8824, 0.8923, 0.7797,
        0.9904, 0.9704], device='cuda:0'),
 tensor(0.8500, device='cuda:0'): tensor([0.9885, 0.9489, 0.9965, 0.9503, 0.8795, 0.9934, 0.9949, 0.9951, 0.8261,
        0.9167, 0.7949, 0.9803, 0.8634, 0.9570, 0.9976, 0.8667, 0.9134, 0.7788,
        0.9951, 0.9697], device='cuda:0'),
 tensor(0.8750, device='cuda:0'): tensor([0.9922, 0.9634, 0.9964, 0.9610, 0.8857, 0.9932, 1.0000, 0.9975, 0.8280,
        0.9265, 0.8173, 0.9850, 0.8718, 0.9609, 0.9972, 0.9000, 0.9274, 0.8039,
        0.9950, 0.9744], device='cuda:0'),
 tensor(0.9000, device='cuda:0'): tensor([0.9921, 0.9618, 0.9963, 0.9662, 0.9333, 1.0000, 1.0000, 1.0000, 0.8346,
        0.9333, 0.8352, 0.9932, 0.8836, 0.9704, 0.9983, 0.9259, 0.9496, 0.8043,
        1.0000, 0.9728], device='cuda:0'),
 tensor(0.9250, device='cuda:0'): tensor([0.9960, 0.9737, 0.9961, 0.9708, 0.9423, 1.0000, 1.0000, 1.0000, 0.8723,
        0.9455, 0.8649, 0.9922, 0.9106, 0.9812, 0.9977, 1.0000, 0.9537, 0.8077,
        1.0000, 0.9781], device='cuda:0'),
 tensor(0.9500, device='cuda:0'): tensor([0.9957, 0.9859, 1.0000, 0.9837, 1.0000, 1.0000, 1.0000, 1.0000, 0.8824,
        0.9250, 0.8269, 1.0000, 0.9394, 0.9934, 0.9960, 1.0000, 0.9495, 0.8983,
        1.0000, 0.9750], device='cuda:0'),
 tensor(0.9750, device='cuda:0'): tensor([0.9953, 1.0000, 1.0000, 0.9908, 1.0000, 1.0000, 1.0000, 1.0000, 0.9167,
        0.9600, 0.8846, 1.0000, 0.9718, 0.9919, 1.0000, 1.0000, 0.9655, 0.8611,
        1.0000, 0.9904], device='cuda:0')}

