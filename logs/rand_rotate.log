Epoch 0
======================
TRAIN:
[0/5717 (0%)] Loss: 0.392399
[1600/5717 (28%)] Loss: 0.080030
[3200/5717 (56%)] Loss: 0.063683
[4800/5717 (84%)] Loss: 0.053557
[5717/5717 (100%)] Loss: 0.068293
Average training loss: 0.07982203933065171
VAL:
[0/5823 (0%)] Loss: 0.034687
[1600/5823 (27%)] Loss: 0.083163
[3200/5823 (55%)] Loss: 0.067866
[4800/5823 (82%)] Loss: 0.039199
[5823/5823 (100%)] Loss: 0.082565
Average validation loss: 0.05479638328888341
AP: 0.6793702144749193
Accuracy: 0.9519577537351881

Epoch 1
======================
TRAIN:
[0/5717 (0%)] Loss: 0.065040
[1600/5717 (28%)] Loss: 0.067650
[3200/5717 (56%)] Loss: 0.041341
[4800/5717 (84%)] Loss: 0.055897
[5717/5717 (100%)] Loss: 0.067733
Average training loss: 0.05890239464653122
VAL:
[0/5823 (0%)] Loss: 0.039874
[1600/5823 (27%)] Loss: 0.024229
[3200/5823 (55%)] Loss: 0.036370
[4800/5823 (82%)] Loss: 0.071262
[5823/5823 (100%)] Loss: 0.048558
Average validation loss: 0.0476194120071071
AP: 0.7446068102030738
Accuracy: 0.9590760776232182

Epoch 2
======================
TRAIN:
[0/5717 (0%)] Loss: 0.050914
[1600/5717 (28%)] Loss: 0.071319
[3200/5717 (56%)] Loss: 0.049647
[4800/5717 (84%)] Loss: 0.041362
[5717/5717 (100%)] Loss: 0.035784
Average training loss: 0.05291608734564348
VAL:
[0/5823 (0%)] Loss: 0.075465
[1600/5823 (27%)] Loss: 0.060609
[3200/5823 (55%)] Loss: 0.036577
[4800/5823 (82%)] Loss: 0.069757
[5823/5823 (100%)] Loss: 0.029361
Average validation loss: 0.04633874279334323
AP: 0.7641519729549308
Accuracy: 0.9606474325948824

Epoch 3
======================
TRAIN:
[0/5717 (0%)] Loss: 0.028401
[1600/5717 (28%)] Loss: 0.060623
[3200/5717 (56%)] Loss: 0.043546
[4800/5717 (84%)] Loss: 0.089312
[5717/5717 (100%)] Loss: 0.038279
Average training loss: 0.049663908349779934
VAL:
[0/5823 (0%)] Loss: 0.046778
[1600/5823 (27%)] Loss: 0.042211
[3200/5823 (55%)] Loss: 0.059103
[4800/5823 (82%)] Loss: 0.049588
[5823/5823 (100%)] Loss: 0.039069
Average validation loss: 0.04478162402993293
AP: 0.7764096915495426
Accuracy: 0.9613858835651726

Epoch 4
======================
TRAIN:
[0/5717 (0%)] Loss: 0.042220
[1600/5717 (28%)] Loss: 0.055590
[3200/5717 (56%)] Loss: 0.036534
[4800/5717 (84%)] Loss: 0.030597
[5717/5717 (100%)] Loss: 0.023868
Average training loss: 0.04814876447190772
VAL:
[0/5823 (0%)] Loss: 0.033718
[1600/5823 (27%)] Loss: 0.024829
[3200/5823 (55%)] Loss: 0.045329
[4800/5823 (82%)] Loss: 0.032472
[5823/5823 (100%)] Loss: 0.024899
Average validation loss: 0.04470915654367143
AP: 0.7856382084001905
Accuracy: 0.9629744118152155

Epoch 5
======================
TRAIN:
[0/5717 (0%)] Loss: 0.080138
[1600/5717 (28%)] Loss: 0.051929
[3200/5717 (56%)] Loss: 0.032867
[4800/5717 (84%)] Loss: 0.039297
[5717/5717 (100%)] Loss: 0.061215
Average training loss: 0.04559114280879706
VAL:
[0/5823 (0%)] Loss: 0.019543
[1600/5823 (27%)] Loss: 0.052517
[3200/5823 (55%)] Loss: 0.014416
[4800/5823 (82%)] Loss: 0.073668
[5823/5823 (100%)] Loss: 0.044089
Average validation loss: 0.04353453520977112
AP: 0.7883791763514069
Accuracy: 0.9630431049287309

Epoch 6
======================
TRAIN:
[0/5717 (0%)] Loss: 0.030704
[1600/5717 (28%)] Loss: 0.039770
[3200/5717 (56%)] Loss: 0.084496
[4800/5717 (84%)] Loss: 0.034908
[5717/5717 (100%)] Loss: 0.063875
Average training loss: 0.04498819046217453
VAL:
[0/5823 (0%)] Loss: 0.050850
[1600/5823 (27%)] Loss: 0.042049
[3200/5823 (55%)] Loss: 0.047830
[4800/5823 (82%)] Loss: 0.051923
[5823/5823 (100%)] Loss: 0.021963
Average validation loss: 0.04149229180228968
AP: 0.7945273756150072
Accuracy: 0.964880645715267

Epoch 7
======================
TRAIN:
[0/5717 (0%)] Loss: 0.028554
[1600/5717 (28%)] Loss: 0.056822
[3200/5717 (56%)] Loss: 0.029614
[4800/5717 (84%)] Loss: 0.034815
[5717/5717 (100%)] Loss: 0.045206
Average training loss: 0.04286097595533291
VAL:
[0/5823 (0%)] Loss: 0.038172
[1600/5823 (27%)] Loss: 0.033876
[3200/5823 (55%)] Loss: 0.068555
[4800/5823 (82%)] Loss: 0.068378
[5823/5823 (100%)] Loss: 0.042726
Average validation loss: 0.04169974333458263
AP: 0.797820351218839
Accuracy: 0.964880645715267

Epoch 8
======================
TRAIN:
[0/5717 (0%)] Loss: 0.030996
[1600/5717 (28%)] Loss: 0.048250
[3200/5717 (56%)] Loss: 0.063634
[4800/5717 (84%)] Loss: 0.019863
[5717/5717 (100%)] Loss: 0.030566
Average training loss: 0.04216916079834833
VAL:
[0/5823 (0%)] Loss: 0.066393
[1600/5823 (27%)] Loss: 0.029705
[3200/5823 (55%)] Loss: 0.030757
[4800/5823 (82%)] Loss: 0.135050
[5823/5823 (100%)] Loss: 0.068731
Average validation loss: 0.04305899172514718
AP: 0.7958043824036457
Accuracy: 0.9638416623733471

Epoch 9
======================
TRAIN:
[0/5717 (0%)] Loss: 0.037885
[1600/5717 (28%)] Loss: 0.028082
[3200/5717 (56%)] Loss: 0.041936
[4800/5717 (84%)] Loss: 0.023282
[5717/5717 (100%)] Loss: 0.083982
Average training loss: 0.0410035473222916
VAL:
[0/5823 (0%)] Loss: 0.060112
[1600/5823 (27%)] Loss: 0.052933
[3200/5823 (55%)] Loss: 0.027656
[4800/5823 (82%)] Loss: 0.017841
[5823/5823 (100%)] Loss: 0.027661
Average validation loss: 0.04175686695776716
AP: 0.8025682310032395
Accuracy: 0.9647260862098574

Epoch 10
======================
TRAIN:
[0/5717 (0%)] Loss: 0.040354
[1600/5717 (28%)] Loss: 0.075533
[3200/5717 (56%)] Loss: 0.050936
[4800/5717 (84%)] Loss: 0.035647
[5717/5717 (100%)] Loss: 0.093829
Average training loss: 0.03899106736835483
VAL:
[0/5823 (0%)] Loss: 0.021812
[1600/5823 (27%)] Loss: 0.048927
[3200/5823 (55%)] Loss: 0.039848
[4800/5823 (82%)] Loss: 0.036039
[5823/5823 (100%)] Loss: 0.018395
Average validation loss: 0.04112618098452503
AP: 0.8021639778312709
Accuracy: 0.9656706165206937

Epoch 11
======================
TRAIN:
[0/5717 (0%)] Loss: 0.020333
[1600/5717 (28%)] Loss: 0.033929
[3200/5717 (56%)] Loss: 0.029744
[4800/5717 (84%)] Loss: 0.037940
[5717/5717 (100%)] Loss: 0.048692
Average training loss: 0.03890134852014847
VAL:
[0/5823 (0%)] Loss: 0.048923
[1600/5823 (27%)] Loss: 0.023869
[3200/5823 (55%)] Loss: 0.022600
[4800/5823 (82%)] Loss: 0.036705
[5823/5823 (100%)] Loss: 0.063370
Average validation loss: 0.040691667989249454
AP: 0.8062634166246523
Accuracy: 0.9663403743774687

Epoch 12
======================
TRAIN:
[0/5717 (0%)] Loss: 0.030536
[1600/5717 (28%)] Loss: 0.029828
[3200/5717 (56%)] Loss: 0.021548
[4800/5717 (84%)] Loss: 0.031411
[5717/5717 (100%)] Loss: 0.026793
Average training loss: 0.037555340211187206
VAL:
[0/5823 (0%)] Loss: 0.042398
[1600/5823 (27%)] Loss: 0.058366
[3200/5823 (55%)] Loss: 0.032417
[4800/5823 (82%)] Loss: 0.067484
[5823/5823 (100%)] Loss: 0.065412
Average validation loss: 0.04115340690215497
AP: 0.8042727439304372
Accuracy: 0.9655332302936631

Epoch 13
======================
TRAIN:
[0/5717 (0%)] Loss: 0.047701
[1600/5717 (28%)] Loss: 0.019135
[3200/5717 (56%)] Loss: 0.027816
[4800/5717 (84%)] Loss: 0.028230
[5717/5717 (100%)] Loss: 0.038590
Average training loss: 0.03749028410423886
VAL:
[0/5823 (0%)] Loss: 0.028244
[1600/5823 (27%)] Loss: 0.084354
[3200/5823 (55%)] Loss: 0.037704
[4800/5823 (82%)] Loss: 0.040581
[5823/5823 (100%)] Loss: 0.027595
Average validation loss: 0.040297115777470784
AP: 0.8109427413189001
Accuracy: 0.9665378670788254

Epoch 14
======================
TRAIN:
[0/5717 (0%)] Loss: 0.067508
[1600/5717 (28%)] Loss: 0.021156
[3200/5717 (56%)] Loss: 0.051369
[4800/5717 (84%)] Loss: 0.024013
[5717/5717 (100%)] Loss: 0.012960
Average training loss: 0.03761259756878123
VAL:
[0/5823 (0%)] Loss: 0.007672
[1600/5823 (27%)] Loss: 0.042237
[3200/5823 (55%)] Loss: 0.055410
[4800/5823 (82%)] Loss: 0.035564
[5823/5823 (100%)] Loss: 0.051222
Average validation loss: 0.04070831306443734
AP: 0.8056546007692131
Accuracy: 0.966082775201786

Epoch 15
======================
TRAIN:
[0/5717 (0%)] Loss: 0.020222
[1600/5717 (28%)] Loss: 0.032626
[3200/5717 (56%)] Loss: 0.015855
[4800/5717 (84%)] Loss: 0.031367
[5717/5717 (100%)] Loss: 0.043939
Average training loss: 0.03734632269511898
VAL:
[0/5823 (0%)] Loss: 0.039411
[1600/5823 (27%)] Loss: 0.056656
[3200/5823 (55%)] Loss: 0.052948
[4800/5823 (82%)] Loss: 0.050060
[5823/5823 (100%)] Loss: 0.068501
Average validation loss: 0.040558770655879525
AP: 0.8089784642915056
Accuracy: 0.9657135497166409

Epoch 16
======================
TRAIN:
[0/5717 (0%)] Loss: 0.026543
[1600/5717 (28%)] Loss: 0.037087
[3200/5717 (56%)] Loss: 0.054613
[4800/5717 (84%)] Loss: 0.033542
[5717/5717 (100%)] Loss: 0.050655
Average training loss: 0.03717098233869651
VAL:
[0/5823 (0%)] Loss: 0.024975
[1600/5823 (27%)] Loss: 0.035972
[3200/5823 (55%)] Loss: 0.033259
[4800/5823 (82%)] Loss: 0.024270
[5823/5823 (100%)] Loss: 0.042268
Average validation loss: 0.040254832011299556
AP: 0.8076299016657538
Accuracy: 0.9662029881504379

Epoch 17
======================
TRAIN:
[0/5717 (0%)] Loss: 0.030994
[1600/5717 (28%)] Loss: 0.030633
[3200/5717 (56%)] Loss: 0.024911
[4800/5717 (84%)] Loss: 0.044729
[5717/5717 (100%)] Loss: 0.057725
Average training loss: 0.036992035686344536
VAL:
[0/5823 (0%)] Loss: 0.049362
[1600/5823 (27%)] Loss: 0.023315
[3200/5823 (55%)] Loss: 0.041556
[4800/5823 (82%)] Loss: 0.025713
[5823/5823 (100%)] Loss: 0.010893
Average validation loss: 0.04059979194585889
AP: 0.8056155572388312
Accuracy: 0.9656963764382621

Epoch 18
======================
TRAIN:
[0/5717 (0%)] Loss: 0.048012
[1600/5717 (28%)] Loss: 0.021137
[3200/5717 (56%)] Loss: 0.024104
[4800/5717 (84%)] Loss: 0.063820
[5717/5717 (100%)] Loss: 0.034243
Average training loss: 0.036557693627070294
VAL:
[0/5823 (0%)] Loss: 0.041447
[1600/5823 (27%)] Loss: 0.037260
[3200/5823 (55%)] Loss: 0.019981
[4800/5823 (82%)] Loss: 0.028344
[5823/5823 (100%)] Loss: 0.015801
Average validation loss: 0.04058731577722458
AP: 0.8055869067733005
Accuracy: 0.9657221363558304

Epoch 19
======================
TRAIN:
[0/5717 (0%)] Loss: 0.027595
[1600/5717 (28%)] Loss: 0.054377
[3200/5717 (56%)] Loss: 0.019307
[4800/5717 (84%)] Loss: 0.020509
[5717/5717 (100%)] Loss: 0.044544
Average training loss: 0.036622660657898945
VAL:
[0/5823 (0%)] Loss: 0.025618
[1600/5823 (27%)] Loss: 0.055060
[3200/5823 (55%)] Loss: 0.062952
[4800/5823 (82%)] Loss: 0.025012
[5823/5823 (100%)] Loss: 0.063324
Average validation loss: 0.04119318707943331
AP: 0.807675511366691
Accuracy: 0.9657393096342092

Epoch 20
======================
TRAIN:
[0/5717 (0%)] Loss: 0.035301
[1600/5717 (28%)] Loss: 0.039820
[3200/5717 (56%)] Loss: 0.025639
[4800/5717 (84%)] Loss: 0.038648
[5717/5717 (100%)] Loss: 0.019105
Average training loss: 0.037191064913685505
VAL:
[0/5823 (0%)] Loss: 0.072892
[1600/5823 (27%)] Loss: 0.037566
[3200/5823 (55%)] Loss: 0.055597
[4800/5823 (82%)] Loss: 0.027186
[5823/5823 (100%)] Loss: 0.040652
Average validation loss: 0.04065011291007337
AP: 0.8096694965953716
Accuracy: 0.9654817104585265

Epoch 21
======================
TRAIN:
[0/5717 (0%)] Loss: 0.039680
[1600/5717 (28%)] Loss: 0.067382
[3200/5717 (56%)] Loss: 0.036293
[4800/5717 (84%)] Loss: 0.049930
[5717/5717 (100%)] Loss: 0.031099
Average training loss: 0.0362297960316072
VAL:
[0/5823 (0%)] Loss: 0.027617
[1600/5823 (27%)] Loss: 0.044096
[3200/5823 (55%)] Loss: 0.049385
[4800/5823 (82%)] Loss: 0.037688
[5823/5823 (100%)] Loss: 0.048370
Average validation loss: 0.03973140438588766
AP: 0.8069410021621753
Accuracy: 0.9665808002747724

Epoch 22
======================
TRAIN:
[0/5717 (0%)] Loss: 0.043320
[1600/5717 (28%)] Loss: 0.020933
[3200/5717 (56%)] Loss: 0.015400
[4800/5717 (84%)] Loss: 0.031346
[5717/5717 (100%)] Loss: 0.039316
Average training loss: 0.036134807917882095
VAL:
[0/5823 (0%)] Loss: 0.042463
[1600/5823 (27%)] Loss: 0.019207
[3200/5823 (55%)] Loss: 0.047395
[4800/5823 (82%)] Loss: 0.029449
[5823/5823 (100%)] Loss: 0.014076
Average validation loss: 0.04013716407564141
AP: 0.8135295946082478
Accuracy: 0.9667267731409926

Epoch 23
======================
TRAIN:
[0/5717 (0%)] Loss: 0.052574
[1600/5717 (28%)] Loss: 0.059271
[3200/5717 (56%)] Loss: 0.025235
[4800/5717 (84%)] Loss: 0.049909
[5717/5717 (100%)] Loss: 0.015653
Average training loss: 0.03638659465953812
VAL:
[0/5823 (0%)] Loss: 0.037411
[1600/5823 (27%)] Loss: 0.030739
[3200/5823 (55%)] Loss: 0.059378
[4800/5823 (82%)] Loss: 0.018736
[5823/5823 (100%)] Loss: 0.041988
Average validation loss: 0.04116006029685345
AP: 0.8088533942798912
Accuracy: 0.9653443242314957

Epoch 24
======================
TRAIN:
[0/5717 (0%)] Loss: 0.029164
[1600/5717 (28%)] Loss: 0.028917
[3200/5717 (56%)] Loss: 0.021515
[4800/5717 (84%)] Loss: 0.033037
[5717/5717 (100%)] Loss: 0.026148
Average training loss: 0.03671461819195664
VAL:
[0/5823 (0%)] Loss: 0.025671
[1600/5823 (27%)] Loss: 0.027613
[3200/5823 (55%)] Loss: 0.034912
[4800/5823 (82%)] Loss: 0.040413
[5823/5823 (100%)] Loss: 0.039078
Average validation loss: 0.04037827979402289
AP: 0.8072503222191691
Accuracy: 0.966409067490984

Epoch 25
======================
TRAIN:
[0/5717 (0%)] Loss: 0.047963
[1600/5717 (28%)] Loss: 0.034370
[3200/5717 (56%)] Loss: 0.038253
[4800/5717 (84%)] Loss: 0.027908
[5717/5717 (100%)] Loss: 0.035197
Average training loss: 0.03655566543965907
VAL:
[0/5823 (0%)] Loss: 0.047197
[1600/5823 (27%)] Loss: 0.047882
[3200/5823 (55%)] Loss: 0.037980
[4800/5823 (82%)] Loss: 0.028669
[5823/5823 (100%)] Loss: 0.094561
Average validation loss: 0.04116430457113413
AP: 0.8093288106054718
Accuracy: 0.9657049630774515

Epoch 26
======================
TRAIN:
[0/5717 (0%)] Loss: 0.033063
[1600/5717 (28%)] Loss: 0.034806
[3200/5717 (56%)] Loss: 0.049655
[4800/5717 (84%)] Loss: 0.030850
[5717/5717 (100%)] Loss: 0.071825
Average training loss: 0.036238336920008794
VAL:
[0/5823 (0%)] Loss: 0.030753
[1600/5823 (27%)] Loss: 0.041901
[3200/5823 (55%)] Loss: 0.032237
[4800/5823 (82%)] Loss: 0.015242
[5823/5823 (100%)] Loss: 0.032878
Average validation loss: 0.04002913461894483
AP: 0.8097809015143205
Accuracy: 0.9664949338828782

Epoch 27
======================
TRAIN:
[0/5717 (0%)] Loss: 0.045060
[1600/5717 (28%)] Loss: 0.023065
[3200/5717 (56%)] Loss: 0.065104
[4800/5717 (84%)] Loss: 0.038849
[5717/5717 (100%)] Loss: 0.048487
Average training loss: 0.03691345396927082
VAL:
[0/5823 (0%)] Loss: 0.025845
[1600/5823 (27%)] Loss: 0.006624
[3200/5823 (55%)] Loss: 0.041393
[4800/5823 (82%)] Loss: 0.065212
[5823/5823 (100%)] Loss: 0.057737
Average validation loss: 0.0404154986244176
AP: 0.8090922040900973
Accuracy: 0.96646917396531

Epoch 28
======================
TRAIN:
[0/5717 (0%)] Loss: 0.043204
[1600/5717 (28%)] Loss: 0.044275
[3200/5717 (56%)] Loss: 0.035255
[4800/5717 (84%)] Loss: 0.026208
[5717/5717 (100%)] Loss: 0.021175
Average training loss: 0.03641061948781664
VAL:
[0/5823 (0%)] Loss: 0.041509
[1600/5823 (27%)] Loss: 0.038590
[3200/5823 (55%)] Loss: 0.055123
[4800/5823 (82%)] Loss: 0.023108
[5823/5823 (100%)] Loss: 0.068901
Average validation loss: 0.040440510107066154
AP: 0.8080273970584559
Accuracy: 0.9664520006869312

Epoch 29
======================
TRAIN:
[0/5717 (0%)] Loss: 0.031422
[1600/5717 (28%)] Loss: 0.036863
[3200/5717 (56%)] Loss: 0.041557
[4800/5717 (84%)] Loss: 0.024931
[5717/5717 (100%)] Loss: 0.038166
Average training loss: 0.03607395325520343
VAL:
[0/5823 (0%)] Loss: 0.044826
[1600/5823 (27%)] Loss: 0.027908
[3200/5823 (55%)] Loss: 0.043625
[4800/5823 (82%)] Loss: 0.052067
[5823/5823 (100%)] Loss: 0.024467
Average validation loss: 0.04035390360257844
AP: 0.8093220284828804
Accuracy: 0.966632320109909

Epoch 30
======================
TRAIN:
[0/5717 (0%)] Loss: 0.027185
[1600/5717 (28%)] Loss: 0.024657
[3200/5717 (56%)] Loss: 0.023463
[4800/5717 (84%)] Loss: 0.037096
[5717/5717 (100%)] Loss: 0.055843
Average training loss: 0.03609628980862094
VAL:
[0/5823 (0%)] Loss: 0.029214
[1600/5823 (27%)] Loss: 0.019946
[3200/5823 (55%)] Loss: 0.068550
[4800/5823 (82%)] Loss: 0.044053
[5823/5823 (100%)] Loss: 0.060946
Average validation loss: 0.04034127408682092
AP: 0.8108391466182757
Accuracy: 0.9658423493044822

Epoch 31
======================
TRAIN:
[0/5717 (0%)] Loss: 0.028914
[1600/5717 (28%)] Loss: 0.011478
[3200/5717 (56%)] Loss: 0.030510
[4800/5717 (84%)] Loss: 0.025147
[5717/5717 (100%)] Loss: 0.052457
Average training loss: 0.036098957400430336
VAL:
[0/5823 (0%)] Loss: 0.054732
[1600/5823 (27%)] Loss: 0.031520
[3200/5823 (55%)] Loss: 0.049606
[4800/5823 (82%)] Loss: 0.015195
[5823/5823 (100%)] Loss: 0.032288
Average validation loss: 0.04037213990283148
AP: 0.8061256301183556
Accuracy: 0.965979735531513

Epoch 32
======================
TRAIN:
[0/5717 (0%)] Loss: 0.036574
[1600/5717 (28%)] Loss: 0.028776
[3200/5717 (56%)] Loss: 0.047492
[4800/5717 (84%)] Loss: 0.056118
[5717/5717 (100%)] Loss: 0.021758
Average training loss: 0.03611870110816472
VAL:
[0/5823 (0%)] Loss: 0.080897
[1600/5823 (27%)] Loss: 0.033828
[3200/5823 (55%)] Loss: 0.045278
[4800/5823 (82%)] Loss: 0.029353
[5823/5823 (100%)] Loss: 0.043301
Average validation loss: 0.040426946873904544
AP: 0.8095244432439311
Accuracy: 0.9657307229950197

Epoch 33
======================
TRAIN:
[0/5717 (0%)] Loss: 0.024386
[1600/5717 (28%)] Loss: 0.046521
[3200/5717 (56%)] Loss: 0.021884
[4800/5717 (84%)] Loss: 0.038997
[5717/5717 (100%)] Loss: 0.034071
Average training loss: 0.03624000596468682
VAL:
[0/5823 (0%)] Loss: 0.032169
[1600/5823 (27%)] Loss: 0.056373
[3200/5823 (55%)] Loss: 0.030961
[4800/5823 (82%)] Loss: 0.018589
[5823/5823 (100%)] Loss: 0.028967
Average validation loss: 0.04049115887188076
AP: 0.8093451377689438
Accuracy: 0.9656963764382621

Epoch 34
======================
TRAIN:
[0/5717 (0%)] Loss: 0.051434
[1600/5717 (28%)] Loss: 0.020246
[3200/5717 (56%)] Loss: 0.043924
[4800/5717 (84%)] Loss: 0.025273
[5717/5717 (100%)] Loss: 0.127324
Average training loss: 0.036820899448976235
VAL:
[0/5823 (0%)] Loss: 0.073517
[1600/5823 (27%)] Loss: 0.035949
[3200/5823 (55%)] Loss: 0.029981
[4800/5823 (82%)] Loss: 0.008023
[5823/5823 (100%)] Loss: 0.058380
Average validation loss: 0.04096151838030482
AP: 0.8048996930330758
Accuracy: 0.9655589902112314

Epoch 35
======================
TRAIN:
[0/5717 (0%)] Loss: 0.026749
[1600/5717 (28%)] Loss: 0.025287
[3200/5717 (56%)] Loss: 0.032960
[4800/5717 (84%)] Loss: 0.029433
[5717/5717 (100%)] Loss: 0.086799
Average training loss: 0.03656249953551101
VAL:
[0/5823 (0%)] Loss: 0.022424
[1600/5823 (27%)] Loss: 0.017126
[3200/5823 (55%)] Loss: 0.024104
[4800/5823 (82%)] Loss: 0.072323
[5823/5823 (100%)] Loss: 0.062174
Average validation loss: 0.040934697656436814
AP: 0.8060220046172539
Accuracy: 0.9659368023355659

Epoch 36
======================
TRAIN:
[0/5717 (0%)] Loss: 0.045646
[1600/5717 (28%)] Loss: 0.030981
[3200/5717 (56%)] Loss: 0.052602
[4800/5717 (84%)] Loss: 0.036513
[5717/5717 (100%)] Loss: 0.021619
Average training loss: 0.03647440608616892
VAL:
[0/5823 (0%)] Loss: 0.032645
[1600/5823 (27%)] Loss: 0.032252
[3200/5823 (55%)] Loss: 0.027453
[4800/5823 (82%)] Loss: 0.047121
[5823/5823 (100%)] Loss: 0.026983
Average validation loss: 0.04042827853917625
AP: 0.8100393732039095
Accuracy: 0.9666237334707196

Epoch 37
======================
TRAIN:
[0/5717 (0%)] Loss: 0.023670
[1600/5717 (28%)] Loss: 0.126347
[3200/5717 (56%)] Loss: 0.018880
[4800/5717 (84%)] Loss: 0.030607
[5717/5717 (100%)] Loss: 0.031526
Average training loss: 0.03609941569059254
VAL:
[0/5823 (0%)] Loss: 0.019382
[1600/5823 (27%)] Loss: 0.041739
[3200/5823 (55%)] Loss: 0.038036
[4800/5823 (82%)] Loss: 0.039537
[5823/5823 (100%)] Loss: 0.051746
Average validation loss: 0.040129264610036595
AP: 0.8099219828187116
Accuracy: 0.9656019234071784

Epoch 38
======================
TRAIN:
[0/5717 (0%)] Loss: 0.056798
[1600/5717 (28%)] Loss: 0.055431
[3200/5717 (56%)] Loss: 0.025060
[4800/5717 (84%)] Loss: 0.028924
[5717/5717 (100%)] Loss: 0.026711
Average training loss: 0.0359922859544208
VAL:
[0/5823 (0%)] Loss: 0.017016
[1600/5823 (27%)] Loss: 0.038521
[3200/5823 (55%)] Loss: 0.030241
[4800/5823 (82%)] Loss: 0.045638
[5823/5823 (100%)] Loss: 0.057929
Average validation loss: 0.040777529998564745
AP: 0.8108777492547101
Accuracy: 0.966142881676112

Epoch 39
======================
TRAIN:
[0/5717 (0%)] Loss: 0.019519
[1600/5717 (28%)] Loss: 0.022670
[3200/5717 (56%)] Loss: 0.052061
[4800/5717 (84%)] Loss: 0.050774
[5717/5717 (100%)] Loss: 0.015100
Average training loss: 0.03643745105270739
VAL:
[0/5823 (0%)] Loss: 0.051525
[1600/5823 (27%)] Loss: 0.023306
[3200/5823 (55%)] Loss: 0.026234
[4800/5823 (82%)] Loss: 0.054821
[5823/5823 (100%)] Loss: 0.055702
Average validation loss: 0.03972919649702937
AP: 0.8122186935892808
Accuracy: 0.9662888545423322

Measuring performance using best weights...
[0/5823 (0%)]
[1600/5823 (27%)]
[3200/5823 (55%)]
[4800/5823 (82%)]
[5823/5823 (100%)]
Tailacc:
{tensor(0.5000, device='cuda:0'): tensor([0.8882, 0.8559, 0.9100, 0.7773, 0.6617, 0.8495, 0.7947, 0.9062, 0.6934,
        0.7482, 0.6333, 0.7829, 0.7822, 0.7702, 0.9118, 0.6057, 0.7832, 0.6085,
        0.8392, 0.8026], device='cuda:0'),
 tensor(0.5250, device='cuda:0'): tensor([0.9027, 0.8622, 0.9118, 0.7806, 0.6772, 0.8820, 0.8099, 0.9118, 0.7092,
        0.7591, 0.6379, 0.7922, 0.7991, 0.7866, 0.9245, 0.6250, 0.7943, 0.6328,
        0.8492, 0.8097], device='cuda:0'),
 tensor(0.5500, device='cuda:0'): tensor([0.9077, 0.8733, 0.9205, 0.7860, 0.6865, 0.9023, 0.8329, 0.9156, 0.7220,
        0.7704, 0.6402, 0.7993, 0.7982, 0.7932, 0.9355, 0.6562, 0.8102, 0.6506,
        0.8583, 0.8235], device='cuda:0'),
 tensor(0.5750, device='cuda:0'): tensor([0.9071, 0.8848, 0.9259, 0.7841, 0.6910, 0.9023, 0.8378, 0.9231, 0.7239,
        0.7761, 0.6452, 0.8202, 0.8173, 0.8052, 0.9420, 0.6645, 0.8195, 0.6731,
        0.8607, 0.8326], device='cuda:0'),
 tensor(0.6000, device='cuda:0'): tensor([0.9185, 0.8837, 0.9414, 0.7955, 0.7059, 0.9123, 0.8424, 0.9326, 0.7445,
        0.7879, 0.6622, 0.8372, 0.8252, 0.8178, 0.9480, 0.6918, 0.8295, 0.6689,
        0.8739, 0.8341], device='cuda:0'),
 tensor(0.6250, device='cuda:0'): tensor([0.9209, 0.8957, 0.9443, 0.8000, 0.7278, 0.9112, 0.8474, 0.9359, 0.7519,
        0.7846, 0.6906, 0.8488, 0.8392, 0.8326, 0.9577, 0.7194, 0.8525, 0.6972,
        0.8836, 0.8413], device='cuda:0'),
 tensor(0.6500, device='cuda:0'): tensor([0.9204, 0.9043, 0.9502, 0.8077, 0.7518, 0.9212, 0.8581, 0.9374, 0.7603,
        0.7891, 0.6992, 0.8638, 0.8434, 0.8512, 0.9626, 0.7273, 0.8583, 0.7143,
        0.8899, 0.8439], device='cuda:0'),
 tensor(0.6750, device='cuda:0'): tensor([0.9258, 0.9122, 0.9495, 0.8116, 0.7664, 0.9321, 0.8716, 0.9433, 0.7611,
        0.8083, 0.7063, 0.8796, 0.8608, 0.8744, 0.9659, 0.7287, 0.8621, 0.7154,
        0.9013, 0.8600], device='cuda:0'),
 tensor(0.7000, device='cuda:0'): tensor([0.9342, 0.9150, 0.9596, 0.8218, 0.7829, 0.9430, 0.8857, 0.9427, 0.7895,
        0.8067, 0.7000, 0.8858, 0.8639, 0.8713, 0.9721, 0.7480, 0.8684, 0.7317,
        0.9256, 0.8549], device='cuda:0'),
 tensor(0.7250, device='cuda:0'): tensor([0.9461, 0.9192, 0.9624, 0.8410, 0.7937, 0.9430, 0.9160, 0.9512, 0.8098,
        0.8276, 0.7091, 0.8875, 0.8723, 0.8744, 0.9758, 0.7647, 0.8649, 0.7311,
        0.9292, 0.8649], device='cuda:0'),
 tensor(0.7500, device='cuda:0'): tensor([0.9516, 0.9223, 0.9691, 0.8490, 0.8182, 0.9545, 0.9249, 0.9599, 0.8150,
        0.8393, 0.7238, 0.8956, 0.8907, 0.8872, 0.9782, 0.7798, 0.8796, 0.7321,
        0.9333, 0.8641], device='cuda:0'),
 tensor(0.7750, device='cuda:0'): tensor([0.9613, 0.9319, 0.9764, 0.8474, 0.8333, 0.9605, 0.9538, 0.9640, 0.8313,
        0.8519, 0.7300, 0.9069, 0.8895, 0.9000, 0.9793, 0.7843, 0.8868, 0.7383,
        0.9320, 0.8920], device='cuda:0'),
 tensor(0.8000, device='cuda:0'): tensor([0.9642, 0.9358, 0.9758, 0.8641, 0.8455, 0.9597, 0.9602, 0.9707, 0.8345,
        0.8558, 0.7474, 0.9133, 0.8920, 0.9081, 0.9803, 0.7857, 0.8922, 0.7647,
        0.9444, 0.9059], device='cuda:0'),
 tensor(0.8250, device='cuda:0'): tensor([0.9642, 0.9337, 0.9796, 0.8626, 0.8641, 0.9597, 0.9680, 0.9783, 0.8473,
        0.8586, 0.7841, 0.9247, 0.9112, 0.9171, 0.9845, 0.8182, 0.9000, 0.7742,
        0.9538, 0.9136], device='cuda:0'),
 tensor(0.8500, device='cuda:0'): tensor([0.9639, 0.9357, 0.9832, 0.8701, 0.8750, 0.9595, 0.9716, 0.9804, 0.8496,
        0.8632, 0.7857, 0.9308, 0.9255, 0.9306, 0.9846, 0.8333, 0.9082, 0.7841,
        0.9634, 0.9236], device='cuda:0'),
 tensor(0.8750, device='cuda:0'): tensor([0.9670, 0.9325, 0.9826, 0.8743, 0.8941, 0.9724, 0.9692, 0.9800, 0.8763,
        0.8667, 0.7703, 0.9451, 0.9299, 0.9518, 0.9855, 0.8375, 0.9082, 0.8272,
        0.9731, 0.9272], device='cuda:0'),
 tensor(0.9000, device='cuda:0'): tensor([0.9737, 0.9408, 0.9865, 0.8988, 0.8974, 0.9716, 0.9716, 0.9794, 0.8947,
        0.8795, 0.7812, 0.9534, 0.9459, 0.9625, 0.9874, 0.8358, 0.9072, 0.8243,
        0.9719, 0.9420], device='cuda:0'),
 tensor(0.9250, device='cuda:0'): tensor([0.9922, 0.9650, 0.9906, 0.9216, 0.9130, 0.9708, 0.9870, 0.9847, 0.8939,
        0.8974, 0.8182, 0.9615, 0.9704, 0.9669, 0.9952, 0.8500, 0.9140, 0.8209,
        0.9822, 0.9538], device='cuda:0'),
 tensor(0.9500, device='cuda:0'): tensor([0.9919, 0.9695, 0.9949, 0.9366, 0.9483, 0.9921, 0.9923, 0.9935, 0.9167,
        0.9412, 0.8163, 0.9782, 0.9688, 0.9784, 0.9972, 0.8654, 0.9302, 0.8269,
        0.9876, 0.9492], device='cuda:0'),
 tensor(0.9750, device='cuda:0'): tensor([0.9955, 0.9836, 0.9943, 0.9667, 0.9556, 1.0000, 1.0000, 1.0000, 0.9583,
        0.9636, 0.8158, 0.9889, 0.9820, 0.9919, 0.9979, 0.8889, 0.9375, 0.8718,
        0.9932, 0.9615], device='cuda:0')}
Best AP: 0.807878482171445
Best Accuracy: 0.9657307229950197
Best weights saved to weights/rand_rotate_weights.pth
Training loss array saved to saves/rand_rotate_train_loss.npy
Validation loss array saved to saves/rand_rotate_val_loss.npy
Filenames saved to saves/rand_rotate_fnames.npy
Model outputs saved to saves/rand_rotate_outputs.pth
Labels saved to saves/rand_rotate_labels.pth
Accuracy saved to saves/rand_rotate_acc.npy
Average precision saved to saves/rand_rotate_ap.npy
Tail accuracy saved to saves/rand_rotate_tailacc.pth
