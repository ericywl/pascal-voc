Epoch 0
======================
TRAIN:
[0/5717 (0%)] Loss: 0.387677
[1600/5717 (28%)] Loss: 0.080958
[3200/5717 (56%)] Loss: 0.058504
[4800/5717 (84%)] Loss: 0.044035
[5717/5717 (100%)] Loss: 0.052354
Average training loss: 0.07128779420798476
VAL:
[0/5823 (0%)] Loss: 0.024987
[1600/5823 (27%)] Loss: 0.065476
[3200/5823 (55%)] Loss: 0.041247
[4800/5823 (82%)] Loss: 0.030599
[5823/5823 (100%)] Loss: 0.049779
Average validation loss: 0.044223583656475766
AP: 0.7765039761642751
Accuracy: 0.9614717499570669

Epoch 1
======================
TRAIN:
[0/5717 (0%)] Loss: 0.055217
[1600/5717 (28%)] Loss: 0.051610
[3200/5717 (56%)] Loss: 0.036450
[4800/5717 (84%)] Loss: 0.044041
[5717/5717 (100%)] Loss: 0.053395
Average training loss: 0.0465699345368397
VAL:
[0/5823 (0%)] Loss: 0.031719
[1600/5823 (27%)] Loss: 0.025437
[3200/5823 (55%)] Loss: 0.028448
[4800/5823 (82%)] Loss: 0.051206
[5823/5823 (100%)] Loss: 0.038650
Average validation loss: 0.03701302368106873
AP: 0.8321046145831059
Accuracy: 0.9687274600721277

Epoch 2
======================
TRAIN:
[0/5717 (0%)] Loss: 0.041345
[1600/5717 (28%)] Loss: 0.039837
[3200/5717 (56%)] Loss: 0.032383
[4800/5717 (84%)] Loss: 0.027231
[5717/5717 (100%)] Loss: 0.018664
Average training loss: 0.038728070511788754
VAL:
[0/5823 (0%)] Loss: 0.068476
[1600/5823 (27%)] Loss: 0.047961
[3200/5823 (55%)] Loss: 0.019559
[4800/5823 (82%)] Loss: 0.036350
[5823/5823 (100%)] Loss: 0.015915
Average validation loss: 0.03484063169274192
AP: 0.8508979220907447
Accuracy: 0.9704362012708226

Epoch 3
======================
TRAIN:
[0/5717 (0%)] Loss: 0.024791
[1600/5717 (28%)] Loss: 0.048835
[3200/5717 (56%)] Loss: 0.034645
[4800/5717 (84%)] Loss: 0.057686
[5717/5717 (100%)] Loss: 0.015431
Average training loss: 0.033832195931329176
VAL:
[0/5823 (0%)] Loss: 0.021297
[1600/5823 (27%)] Loss: 0.057524
[3200/5823 (55%)] Loss: 0.048640
[4800/5823 (82%)] Loss: 0.040644
[5823/5823 (100%)] Loss: 0.018419
Average validation loss: 0.0320738970486263
AP: 0.8631998807028849
Accuracy: 0.9724025416452

Epoch 4
======================
TRAIN:
[0/5717 (0%)] Loss: 0.023144
[1600/5717 (28%)] Loss: 0.024608
[3200/5717 (56%)] Loss: 0.035815
[4800/5717 (84%)] Loss: 0.031541
[5717/5717 (100%)] Loss: 0.020083
Average training loss: 0.030408231997406564
VAL:
[0/5823 (0%)] Loss: 0.024595
[1600/5823 (27%)] Loss: 0.016122
[3200/5823 (55%)] Loss: 0.018948
[4800/5823 (82%)] Loss: 0.016973
[5823/5823 (100%)] Loss: 0.012463
Average validation loss: 0.03147259337320965
AP: 0.8675829147074273
Accuracy: 0.9730551262235961

Epoch 5
======================
TRAIN:
[0/5717 (0%)] Loss: 0.041156
[1600/5717 (28%)] Loss: 0.024690
[3200/5717 (56%)] Loss: 0.024844
[4800/5717 (84%)] Loss: 0.030576
[5717/5717 (100%)] Loss: 0.048827
Average training loss: 0.026995986398517878
VAL:
[0/5823 (0%)] Loss: 0.009570
[1600/5823 (27%)] Loss: 0.060735
[3200/5823 (55%)] Loss: 0.017625
[4800/5823 (82%)] Loss: 0.036160
[5823/5823 (100%)] Loss: 0.025535
Average validation loss: 0.03148050982425767
AP: 0.8724724052662205
Accuracy: 0.973115232697922

Epoch 6
======================
TRAIN:
[0/5717 (0%)] Loss: 0.017359
[1600/5717 (28%)] Loss: 0.020067
[3200/5717 (56%)] Loss: 0.031518
[4800/5717 (84%)] Loss: 0.018332
[5717/5717 (100%)] Loss: 0.041817
Average training loss: 0.02441285059793846
VAL:
[0/5823 (0%)] Loss: 0.042327
[1600/5823 (27%)] Loss: 0.021310
[3200/5823 (55%)] Loss: 0.034327
[4800/5823 (82%)] Loss: 0.039233
[5823/5823 (100%)] Loss: 0.013173
Average validation loss: 0.03040770990108805
AP: 0.8754408605828112
Accuracy: 0.9736819508844239

Epoch 7
======================
TRAIN:
[0/5717 (0%)] Loss: 0.009937
[1600/5717 (28%)] Loss: 0.011824
[3200/5717 (56%)] Loss: 0.012457
[4800/5717 (84%)] Loss: 0.021580
[5717/5717 (100%)] Loss: 0.029545
Average training loss: 0.02201968490413123
VAL:
[0/5823 (0%)] Loss: 0.034240
[1600/5823 (27%)] Loss: 0.031972
[3200/5823 (55%)] Loss: 0.059835
[4800/5823 (82%)] Loss: 0.039271
[5823/5823 (100%)] Loss: 0.028245
Average validation loss: 0.03000673637111354
AP: 0.8778946198827505
Accuracy: 0.9745492014425554

Epoch 8
======================
TRAIN:
[0/5717 (0%)] Loss: 0.012467
[1600/5717 (28%)] Loss: 0.022676
[3200/5717 (56%)] Loss: 0.030170
[4800/5717 (84%)] Loss: 0.015526
[5717/5717 (100%)] Loss: 0.013219
Average training loss: 0.019027114109872106
VAL:
[0/5823 (0%)] Loss: 0.022205
[1600/5823 (27%)] Loss: 0.042271
[3200/5823 (55%)] Loss: 0.020547
[4800/5823 (82%)] Loss: 0.072334
[5823/5823 (100%)] Loss: 0.021481
Average validation loss: 0.030589989721033068
AP: 0.8780529569110682
Accuracy: 0.9741370427614632

Epoch 9
======================
TRAIN:
[0/5717 (0%)] Loss: 0.011763
[1600/5717 (28%)] Loss: 0.009739
[3200/5717 (56%)] Loss: 0.017515
[4800/5717 (84%)] Loss: 0.011002
[5717/5717 (100%)] Loss: 0.060139
Average training loss: 0.017338863995994304
VAL:
[0/5823 (0%)] Loss: 0.050288
[1600/5823 (27%)] Loss: 0.029822
[3200/5823 (55%)] Loss: 0.025084
[4800/5823 (82%)] Loss: 0.004514
[5823/5823 (100%)] Loss: 0.013524
Average validation loss: 0.03007109828419973
AP: 0.8809265364862151
Accuracy: 0.9746007212776919

Epoch 10
======================
TRAIN:
[0/5717 (0%)] Loss: 0.013142
[1600/5717 (28%)] Loss: 0.023512
[3200/5717 (56%)] Loss: 0.025368
[4800/5717 (84%)] Loss: 0.009802
[5717/5717 (100%)] Loss: 0.069783
Average training loss: 0.015043454422530803
VAL:
[0/5823 (0%)] Loss: 0.023322
[1600/5823 (27%)] Loss: 0.027367
[3200/5823 (55%)] Loss: 0.022574
[4800/5823 (82%)] Loss: 0.025216
[5823/5823 (100%)] Loss: 0.014417
Average validation loss: 0.029796999971290213
AP: 0.8807222760752885
Accuracy: 0.9750472265155418

Epoch 11
======================
TRAIN:
[0/5717 (0%)] Loss: 0.007757
[1600/5717 (28%)] Loss: 0.010162
[3200/5717 (56%)] Loss: 0.011669
[4800/5717 (84%)] Loss: 0.006888
[5717/5717 (100%)] Loss: 0.015940
Average training loss: 0.01450730121264664
VAL:
[0/5823 (0%)] Loss: 0.042874
[1600/5823 (27%)] Loss: 0.013965
[3200/5823 (55%)] Loss: 0.021449
[4800/5823 (82%)] Loss: 0.013423
[5823/5823 (100%)] Loss: 0.033590
Average validation loss: 0.02971233731547657
AP: 0.8812952348546857
Accuracy: 0.975356345526361

Epoch 12
======================
TRAIN:
[0/5717 (0%)] Loss: 0.008908
[1600/5717 (28%)] Loss: 0.013448
[3200/5717 (56%)] Loss: 0.007475
[4800/5717 (84%)] Loss: 0.007405
[5717/5717 (100%)] Loss: 0.011503
Average training loss: 0.01438070983020263
VAL:
[0/5823 (0%)] Loss: 0.033946
[1600/5823 (27%)] Loss: 0.035960
[3200/5823 (55%)] Loss: 0.029433
[4800/5823 (82%)] Loss: 0.032237
[5823/5823 (100%)] Loss: 0.051678
Average validation loss: 0.030048180393750554
AP: 0.8813570064547398
Accuracy: 0.9751588528250043

Epoch 13
======================
TRAIN:
[0/5717 (0%)] Loss: 0.016779
[1600/5717 (28%)] Loss: 0.007684
[3200/5717 (56%)] Loss: 0.011385
[4800/5717 (84%)] Loss: 0.016388
[5717/5717 (100%)] Loss: 0.016576
Average training loss: 0.014038383252137191
VAL:
[0/5823 (0%)] Loss: 0.013800
[1600/5823 (27%)] Loss: 0.081653
[3200/5823 (55%)] Loss: 0.022053
[4800/5823 (82%)] Loss: 0.054423
[5823/5823 (100%)] Loss: 0.008091
Average validation loss: 0.029436444740865257
AP: 0.8818210708421084
Accuracy: 0.9754765584750129

Epoch 14
======================
TRAIN:
[0/5717 (0%)] Loss: 0.031634
[1600/5717 (28%)] Loss: 0.006828
[3200/5717 (56%)] Loss: 0.011703
[4800/5717 (84%)] Loss: 0.007017
[5717/5717 (100%)] Loss: 0.004270
Average training loss: 0.01405181730055361
VAL:
[0/5823 (0%)] Loss: 0.006378
[1600/5823 (27%)] Loss: 0.025795
[3200/5823 (55%)] Loss: 0.028357
[4800/5823 (82%)] Loss: 0.031338
[5823/5823 (100%)] Loss: 0.039373
Average validation loss: 0.029778660201482926
AP: 0.8810151550890586
Accuracy: 0.9750643997939207

Epoch 15
======================
TRAIN:
[0/5717 (0%)] Loss: 0.010229
[1600/5717 (28%)] Loss: 0.010657
[3200/5717 (56%)] Loss: 0.004756
[4800/5717 (84%)] Loss: 0.019266
[5717/5717 (100%)] Loss: 0.025875
Average training loss: 0.013796943785635741
VAL:
[0/5823 (0%)] Loss: 0.056835
[1600/5823 (27%)] Loss: 0.026322
[3200/5823 (55%)] Loss: 0.047623
[4800/5823 (82%)] Loss: 0.017857
[5823/5823 (100%)] Loss: 0.068183
Average validation loss: 0.030049637804040685
AP: 0.8819342171453273
Accuracy: 0.9752704791344667

Epoch 16
======================
TRAIN:
[0/5717 (0%)] Loss: 0.012134
[1600/5717 (28%)] Loss: 0.008246
[3200/5717 (56%)] Loss: 0.012676
[4800/5717 (84%)] Loss: 0.005904
[5717/5717 (100%)] Loss: 0.029435
Average training loss: 0.013555434638946935
VAL:
[0/5823 (0%)] Loss: 0.019823
[1600/5823 (27%)] Loss: 0.036772
[3200/5823 (55%)] Loss: 0.029060
[4800/5823 (82%)] Loss: 0.013012
[5823/5823 (100%)] Loss: 0.028491
Average validation loss: 0.029475437715178826
AP: 0.8818152210413479
Accuracy: 0.975356345526361

Epoch 17
======================
TRAIN:
[0/5717 (0%)] Loss: 0.015001
[1600/5717 (28%)] Loss: 0.009814
[3200/5717 (56%)] Loss: 0.009322
[4800/5717 (84%)] Loss: 0.019336
[5717/5717 (100%)] Loss: 0.017960
Average training loss: 0.013264784888996111
VAL:
[0/5823 (0%)] Loss: 0.039198
[1600/5823 (27%)] Loss: 0.028868
[3200/5823 (55%)] Loss: 0.033342
[4800/5823 (82%)] Loss: 0.009914
[5823/5823 (100%)] Loss: 0.006085
Average validation loss: 0.02953626637367511
AP: 0.8817123082625593
Accuracy: 0.9751846127425725

Epoch 18
======================
TRAIN:
[0/5717 (0%)] Loss: 0.023753
[1600/5717 (28%)] Loss: 0.009355
[3200/5717 (56%)] Loss: 0.005013
[4800/5717 (84%)] Loss: 0.025923
[5717/5717 (100%)] Loss: 0.013047
Average training loss: 0.012933603724321494
VAL:
[0/5823 (0%)] Loss: 0.018167
[1600/5823 (27%)] Loss: 0.028647
[3200/5823 (55%)] Loss: 0.013714
[4800/5823 (82%)] Loss: 0.021081
[5823/5823 (100%)] Loss: 0.011988
Average validation loss: 0.030149219296987752
AP: 0.8818722265864282
Accuracy: 0.9749356002060794

Epoch 19
======================
TRAIN:
[0/5717 (0%)] Loss: 0.009565
[1600/5717 (28%)] Loss: 0.013526
[3200/5717 (56%)] Loss: 0.010927
[4800/5717 (84%)] Loss: 0.013501
[5717/5717 (100%)] Loss: 0.012129
Average training loss: 0.012848826133730737
VAL:
[0/5823 (0%)] Loss: 0.013229
[1600/5823 (27%)] Loss: 0.051357
[3200/5823 (55%)] Loss: 0.031121
[4800/5823 (82%)] Loss: 0.031008
[5823/5823 (100%)] Loss: 0.034018
Average validation loss: 0.02988287749070838
AP: 0.8824266143138754
Accuracy: 0.9750815730722995

Epoch 20
======================
TRAIN:
[0/5717 (0%)] Loss: 0.010168
[1600/5717 (28%)] Loss: 0.011300
[3200/5717 (56%)] Loss: 0.009580
[4800/5717 (84%)] Loss: 0.006291
[5717/5717 (100%)] Loss: 0.014645
Average training loss: 0.012803045006052076
VAL:
[0/5823 (0%)] Loss: 0.079255
[1600/5823 (27%)] Loss: 0.029765
[3200/5823 (55%)] Loss: 0.032338
[4800/5823 (82%)] Loss: 0.030716
[5823/5823 (100%)] Loss: 0.032111
Average validation loss: 0.030216244580914972
AP: 0.8820733221861486
Accuracy: 0.974703760947965

Epoch 21
======================
TRAIN:
[0/5717 (0%)] Loss: 0.007630
[1600/5717 (28%)] Loss: 0.033638
[3200/5717 (56%)] Loss: 0.009232
[4800/5717 (84%)] Loss: 0.014343
[5717/5717 (100%)] Loss: 0.011121
Average training loss: 0.012688361635184163
VAL:
[0/5823 (0%)] Loss: 0.013768
[1600/5823 (27%)] Loss: 0.042502
[3200/5823 (55%)] Loss: 0.023850
[4800/5823 (82%)] Loss: 0.026039
[5823/5823 (100%)] Loss: 0.029238
Average validation loss: 0.02955376166321982
AP: 0.8821936644430776
Accuracy: 0.9752704791344667

Epoch 22
======================
TRAIN:
[0/5717 (0%)] Loss: 0.023237
[1600/5717 (28%)] Loss: 0.008018
[3200/5717 (56%)] Loss: 0.005931
[4800/5717 (84%)] Loss: 0.009356
[5717/5717 (100%)] Loss: 0.019460
Average training loss: 0.012942195020394622
VAL:
[0/5823 (0%)] Loss: 0.045280
[1600/5823 (27%)] Loss: 0.008409
[3200/5823 (55%)] Loss: 0.026819
[4800/5823 (82%)] Loss: 0.022356
[5823/5823 (100%)] Loss: 0.003789
Average validation loss: 0.029938439636140714
AP: 0.8825885545155742
Accuracy: 0.975459385196634

Epoch 23
======================
TRAIN:
[0/5717 (0%)] Loss: 0.023020
[1600/5717 (28%)] Loss: 0.031023
[3200/5717 (56%)] Loss: 0.010565
[4800/5717 (84%)] Loss: 0.011146
[5717/5717 (100%)] Loss: 0.018867
Average training loss: 0.012975574037307626
VAL:
[0/5823 (0%)] Loss: 0.014597
[1600/5823 (27%)] Loss: 0.008586
[3200/5823 (55%)] Loss: 0.027839
[4800/5823 (82%)] Loss: 0.018827
[5823/5823 (100%)] Loss: 0.035050
Average validation loss: 0.030272931606664864
AP: 0.881575382321285
Accuracy: 0.9747552807831015

Epoch 24
======================
TRAIN:
[0/5717 (0%)] Loss: 0.006991
[1600/5717 (28%)] Loss: 0.011145
[3200/5717 (56%)] Loss: 0.011449
[4800/5717 (84%)] Loss: 0.013528
[5717/5717 (100%)] Loss: 0.009004
Average training loss: 0.01282732578424307
VAL:
[0/5823 (0%)] Loss: 0.031457
[1600/5823 (27%)] Loss: 0.031165
[3200/5823 (55%)] Loss: 0.022761
[4800/5823 (82%)] Loss: 0.028428
[5823/5823 (100%)] Loss: 0.026865
Average validation loss: 0.029929710952513903
AP: 0.8815268617756987
Accuracy: 0.9754164520006869

Epoch 25
======================
TRAIN:
[0/5717 (0%)] Loss: 0.007003
[1600/5717 (28%)] Loss: 0.008697
[3200/5717 (56%)] Loss: 0.022285
[4800/5717 (84%)] Loss: 0.012163
[5717/5717 (100%)] Loss: 0.015752
Average training loss: 0.012831131175446969
VAL:
[0/5823 (0%)] Loss: 0.042149
[1600/5823 (27%)] Loss: 0.039039
[3200/5823 (55%)] Loss: 0.022549
[4800/5823 (82%)] Loss: 0.031370
[5823/5823 (100%)] Loss: 0.081570
Average validation loss: 0.030382570768719294
AP: 0.8816193697328258
Accuracy: 0.9745492014425554

Epoch 26
======================
TRAIN:
[0/5717 (0%)] Loss: 0.021507
[1600/5717 (28%)] Loss: 0.009192
[3200/5717 (56%)] Loss: 0.009478
[4800/5717 (84%)] Loss: 0.014570
[5717/5717 (100%)] Loss: 0.035407
Average training loss: 0.01246868837429406
VAL:
[0/5823 (0%)] Loss: 0.027447
[1600/5823 (27%)] Loss: 0.034615
[3200/5823 (55%)] Loss: 0.032717
[4800/5823 (82%)] Loss: 0.023594
[5823/5823 (100%)] Loss: 0.038915
Average validation loss: 0.029921205128750322
AP: 0.8816395759291987
Accuracy: 0.9750214665979735

Epoch 27
======================
TRAIN:
[0/5717 (0%)] Loss: 0.012264
[1600/5717 (28%)] Loss: 0.007442
[3200/5717 (56%)] Loss: 0.029037
[4800/5717 (84%)] Loss: 0.013877
[5717/5717 (100%)] Loss: 0.039105
Average training loss: 0.012528284259101415
VAL:
[0/5823 (0%)] Loss: 0.016827
[1600/5823 (27%)] Loss: 0.008229
[3200/5823 (55%)] Loss: 0.021416
[4800/5823 (82%)] Loss: 0.030184
[5823/5823 (100%)] Loss: 0.048826
Average validation loss: 0.029909143710808297
AP: 0.8821561455943518
Accuracy: 0.975193199381762

Epoch 28
======================
TRAIN:
[0/5717 (0%)] Loss: 0.012041
[1600/5717 (28%)] Loss: 0.025586
[3200/5717 (56%)] Loss: 0.006924
[4800/5717 (84%)] Loss: 0.008202
[5717/5717 (100%)] Loss: 0.006643
Average training loss: 0.012625591305794416
VAL:
[0/5823 (0%)] Loss: 0.010197
[1600/5823 (27%)] Loss: 0.035349
[3200/5823 (55%)] Loss: 0.027435
[4800/5823 (82%)] Loss: 0.014573
[5823/5823 (100%)] Loss: 0.075425
Average validation loss: 0.02976908290357032
AP: 0.8815668950993929
Accuracy: 0.9754078653614975

Epoch 29
======================
TRAIN:
[0/5717 (0%)] Loss: 0.011545
[1600/5717 (28%)] Loss: 0.010448
[3200/5717 (56%)] Loss: 0.009849
[4800/5717 (84%)] Loss: 0.013294
[5717/5717 (100%)] Loss: 0.029381
Average training loss: 0.012527215832167052
VAL:
[0/5823 (0%)] Loss: 0.058060
[1600/5823 (27%)] Loss: 0.021456
[3200/5823 (55%)] Loss: 0.028561
[4800/5823 (82%)] Loss: 0.027764
[5823/5823 (100%)] Loss: 0.023494
Average validation loss: 0.02998211882799956
AP: 0.881719375233462
Accuracy: 0.9752533058560879

Epoch 30
======================
TRAIN:
[0/5717 (0%)] Loss: 0.012226
[1600/5717 (28%)] Loss: 0.007716
[3200/5717 (56%)] Loss: 0.008260
[4800/5717 (84%)] Loss: 0.007154
[5717/5717 (100%)] Loss: 0.027765
Average training loss: 0.012653712010649326
VAL:
[0/5823 (0%)] Loss: 0.012183
[1600/5823 (27%)] Loss: 0.018764
[3200/5823 (55%)] Loss: 0.060694
[4800/5823 (82%)] Loss: 0.032016
[5823/5823 (100%)] Loss: 0.043400
Average validation loss: 0.030249641788291877
AP: 0.882353106378323
Accuracy: 0.9749098402885111

Epoch 31
======================
TRAIN:
[0/5717 (0%)] Loss: 0.007718
[1600/5717 (28%)] Loss: 0.004269
[3200/5717 (56%)] Loss: 0.011750
[4800/5717 (84%)] Loss: 0.009183
[5717/5717 (100%)] Loss: 0.026224
Average training loss: 0.012442887102260249
VAL:
[0/5823 (0%)] Loss: 0.028949
[1600/5823 (27%)] Loss: 0.023642
[3200/5823 (55%)] Loss: 0.046707
[4800/5823 (82%)] Loss: 0.010295
[5823/5823 (100%)] Loss: 0.009552
Average validation loss: 0.0297600308687114
AP: 0.8817600884855853
Accuracy: 0.9753305856087927

Epoch 32
======================
TRAIN:
[0/5717 (0%)] Loss: 0.008698
[1600/5717 (28%)] Loss: 0.008148
[3200/5717 (56%)] Loss: 0.021116
[4800/5717 (84%)] Loss: 0.010127
[5717/5717 (100%)] Loss: 0.010151
Average training loss: 0.012607132007491651
VAL:
[0/5823 (0%)] Loss: 0.053039
[1600/5823 (27%)] Loss: 0.017767
[3200/5823 (55%)] Loss: 0.054712
[4800/5823 (82%)] Loss: 0.017807
[5823/5823 (100%)] Loss: 0.039247
Average validation loss: 0.030142381424621608
AP: 0.88215561439425
Accuracy: 0.9751245062682466

Epoch 33
======================
TRAIN:
[0/5717 (0%)] Loss: 0.010029
[1600/5717 (28%)] Loss: 0.018322
[3200/5717 (56%)] Loss: 0.019901
[4800/5717 (84%)] Loss: 0.015716
[5717/5717 (100%)] Loss: 0.009104
Average training loss: 0.012647830341271796
VAL:
[0/5823 (0%)] Loss: 0.042179
[1600/5823 (27%)] Loss: 0.065065
[3200/5823 (55%)] Loss: 0.003119
[4800/5823 (82%)] Loss: 0.022637
[5823/5823 (100%)] Loss: 0.016939
Average validation loss: 0.03037791871683222
AP: 0.8814545899701605
Accuracy: 0.9749184269277005

Epoch 34
======================
TRAIN:
[0/5717 (0%)] Loss: 0.007440
[1600/5717 (28%)] Loss: 0.007003
[3200/5717 (56%)] Loss: 0.008288
[4800/5717 (84%)] Loss: 0.006905
[5717/5717 (100%)] Loss: 0.081692
Average training loss: 0.01284512030514335
VAL:
[0/5823 (0%)] Loss: 0.027756
[1600/5823 (27%)] Loss: 0.018002
[3200/5823 (55%)] Loss: 0.025886
[4800/5823 (82%)] Loss: 0.004456
[5823/5823 (100%)] Loss: 0.040457
Average validation loss: 0.029677379503462383
AP: 0.8818869589834939
Accuracy: 0.9754507985574447

Epoch 35
======================
TRAIN:
[0/5717 (0%)] Loss: 0.004999
[1600/5717 (28%)] Loss: 0.005189
[3200/5717 (56%)] Loss: 0.010278
[4800/5717 (84%)] Loss: 0.011981
[5717/5717 (100%)] Loss: 0.028945
Average training loss: 0.012779778833468477
VAL:
[0/5823 (0%)] Loss: 0.023643
[1600/5823 (27%)] Loss: 0.004378
[3200/5823 (55%)] Loss: 0.013321
[4800/5823 (82%)] Loss: 0.062359
[5823/5823 (100%)] Loss: 0.038868
Average validation loss: 0.030106326851387415
AP: 0.8814226574217839
Accuracy: 0.9754078653614975

Epoch 36
======================
TRAIN:
[0/5717 (0%)] Loss: 0.019669
[1600/5717 (28%)] Loss: 0.010399
[3200/5717 (56%)] Loss: 0.015839
[4800/5717 (84%)] Loss: 0.023229
[5717/5717 (100%)] Loss: 0.010712
Average training loss: 0.012652703909971913
VAL:
[0/5823 (0%)] Loss: 0.007672
[1600/5823 (27%)] Loss: 0.011469
[3200/5823 (55%)] Loss: 0.028112
[4800/5823 (82%)] Loss: 0.032049
[5823/5823 (100%)] Loss: 0.017411
Average validation loss: 0.030002024841551147
AP: 0.882120721774638
Accuracy: 0.974866907092564

Epoch 37
======================
TRAIN:
[0/5717 (0%)] Loss: 0.007167
[1600/5717 (28%)] Loss: 0.051536
[3200/5717 (56%)] Loss: 0.008257
[4800/5717 (84%)] Loss: 0.011950
[5717/5717 (100%)] Loss: 0.011321
Average training loss: 0.012429329915415052
VAL:
[0/5823 (0%)] Loss: 0.011067
[1600/5823 (27%)] Loss: 0.018416
[3200/5823 (55%)] Loss: 0.044719
[4800/5823 (82%)] Loss: 0.022134
[5823/5823 (100%)] Loss: 0.016830
Average validation loss: 0.030230101318531006
AP: 0.8814817297041652
Accuracy: 0.9744976816074189

Epoch 38
======================
TRAIN:
[0/5717 (0%)] Loss: 0.029970
[1600/5717 (28%)] Loss: 0.012722
[3200/5717 (56%)] Loss: 0.012548
[4800/5717 (84%)] Loss: 0.008406
[5717/5717 (100%)] Loss: 0.012282
Average training loss: 0.012591442947725316
VAL:
[0/5823 (0%)] Loss: 0.017538
[1600/5823 (27%)] Loss: 0.042101
[3200/5823 (55%)] Loss: 0.021092
[4800/5823 (82%)] Loss: 0.042665
[5823/5823 (100%)] Loss: 0.068174
Average validation loss: 0.029929145373299125
AP: 0.8822136521491865
Accuracy: 0.9752618924952774

Epoch 39
======================
TRAIN:
[0/5717 (0%)] Loss: 0.005024
[1600/5717 (28%)] Loss: 0.009559
[3200/5717 (56%)] Loss: 0.017561
[4800/5717 (84%)] Loss: 0.017628
[5717/5717 (100%)] Loss: 0.005290
Average training loss: 0.012655873537402261
VAL:
[0/5823 (0%)] Loss: 0.026797
[1600/5823 (27%)] Loss: 0.013018
[3200/5823 (55%)] Loss: 0.009133
[4800/5823 (82%)] Loss: 0.033900
[5823/5823 (100%)] Loss: 0.036228
Average validation loss: 0.029760919561850133
AP: 0.8821460504347555
Accuracy: 0.9755366649493389

Measuring performance using best weights...
[0/5823 (0%)]
[1600/5823 (27%)]
[3200/5823 (55%)]
[4800/5823 (82%)]
[5823/5823 (100%)]
Tailacc:
{tensor(0.5000, device='cuda:0'): tensor([0.9310, 0.8833, 0.9701, 0.8333, 0.7080, 0.9516, 0.8656, 0.9590, 0.7683,
        0.7756, 0.7023, 0.8922, 0.8816, 0.8340, 0.9392, 0.6482, 0.8269, 0.6534,
        0.9266, 0.8766], device='cuda:0'),
 tensor(0.5250, device='cuda:0'): tensor([0.9446, 0.8866, 0.9758, 0.8462, 0.7068, 0.9620, 0.8719, 0.9588, 0.7760,
        0.7857, 0.7028, 0.8987, 0.8884, 0.8471, 0.9476, 0.6649, 0.8431, 0.6585,
        0.9302, 0.8870], device='cuda:0'),
 tensor(0.5500, device='cuda:0'): tensor([0.9443, 0.8889, 0.9787, 0.8522, 0.7171, 0.9670, 0.8771, 0.9606, 0.7823,
        0.7987, 0.7039, 0.9067, 0.8921, 0.8498, 0.9535, 0.6919, 0.8421, 0.6667,
        0.9333, 0.8899], device='cuda:0'),
 tensor(0.5750, device='cuda:0'): tensor([0.9467, 0.8913, 0.9787, 0.8590, 0.7205, 0.9724, 0.8854, 0.9642, 0.7883,
        0.8069, 0.7039, 0.9101, 0.8958, 0.8577, 0.9630, 0.7079, 0.8533, 0.6781,
        0.9442, 0.8929], device='cuda:0'),
 tensor(0.6000, device='cuda:0'): tensor([0.9552, 0.8947, 0.9785, 0.8584, 0.7328, 0.9777, 0.8883, 0.9742, 0.7822,
        0.8028, 0.7059, 0.9105, 0.8958, 0.8566, 0.9699, 0.7184, 0.8707, 0.6800,
        0.9478, 0.9041], device='cuda:0'),
 tensor(0.6250, device='cuda:0'): tensor([0.9551, 0.8978, 0.9783, 0.8655, 0.7468, 0.9775, 0.8980, 0.9741, 0.7922,
        0.8116, 0.7121, 0.9192, 0.9025, 0.8661, 0.9748, 0.7193, 0.8767, 0.6944,
        0.9590, 0.9083], device='cuda:0'),
 tensor(0.6500, device='cuda:0'): tensor([0.9580, 0.9058, 0.9812, 0.8649, 0.7588, 0.9775, 0.9021, 0.9740, 0.8083,
        0.8074, 0.7240, 0.9235, 0.9099, 0.8723, 0.9782, 0.7346, 0.8889, 0.7081,
        0.9630, 0.9167], device='cuda:0'),
 tensor(0.6750, device='cuda:0'): tensor([0.9578, 0.9091, 0.9809, 0.8727, 0.7647, 0.9774, 0.9201, 0.9802, 0.8146,
        0.8195, 0.7391, 0.9292, 0.9177, 0.8755, 0.9797, 0.7436, 0.8889, 0.7073,
        0.9627, 0.9167], device='cuda:0'),
 tensor(0.7000, device='cuda:0'): tensor([0.9607, 0.9083, 0.9839, 0.8716, 0.7826, 0.9773, 0.9263, 0.9799, 0.8105,
        0.8308, 0.7598, 0.9385, 0.9214, 0.8788, 0.9819, 0.7500, 0.9007, 0.7164,
        0.9625, 0.9206], device='cuda:0'),
 tensor(0.7250, device='cuda:0'): tensor([0.9636, 0.9163, 0.9871, 0.8698, 0.8000, 0.9828, 0.9388, 0.9886, 0.8102,
        0.8320, 0.7598, 0.9428, 0.9207, 0.8821, 0.9835, 0.7552, 0.9007, 0.7200,
        0.9622, 0.9202], device='cuda:0'),
 tensor(0.7500, device='cuda:0'): tensor([0.9694, 0.9289, 0.9870, 0.8821, 0.8010, 0.9827, 0.9403, 0.9930, 0.8359,
        0.8443, 0.7630, 0.9443, 0.9234, 0.8855, 0.9844, 0.7664, 0.9065, 0.7216,
        0.9662, 0.9194], device='cuda:0'),
 tensor(0.7750, device='cuda:0'): tensor([0.9752, 0.9510, 0.9901, 0.8863, 0.8021, 0.9827, 0.9511, 0.9953, 0.8692,
        0.8583, 0.7784, 0.9490, 0.9266, 0.8955, 0.9874, 0.7704, 0.9191, 0.7166,
        0.9701, 0.9275], device='cuda:0'),
 tensor(0.8000, device='cuda:0'): tensor([0.9748, 0.9598, 0.9900, 0.8905, 0.8000, 0.9882, 0.9531, 0.9952, 0.8899,
        0.8793, 0.7744, 0.9520, 0.9252, 0.8950, 0.9906, 0.7846, 0.9185, 0.7278,
        0.9740, 0.9406], device='cuda:0'),
 tensor(0.8250, device='cuda:0'): tensor([0.9747, 0.9594, 0.9932, 0.9020, 0.7955, 0.9880, 0.9581, 0.9976, 0.9005,
        0.8807, 0.7911, 0.9531, 0.9330, 0.9028, 0.9910, 0.8033, 0.9173, 0.7267,
        0.9780, 0.9450], device='cuda:0'),
 tensor(0.8500, device='cuda:0'): tensor([0.9806, 0.9681, 0.9931, 0.9146, 0.8171, 0.9880, 0.9664, 0.9975, 0.9045,
        0.8879, 0.7933, 0.9620, 0.9505, 0.9151, 0.9921, 0.8017, 0.9375, 0.7423,
        0.9778, 0.9442], device='cuda:0'),
 tensor(0.8750, device='cuda:0'): tensor([0.9804, 0.9674, 0.9964, 0.9184, 0.8456, 0.9880, 0.9716, 1.0000, 0.9050,
        0.8932, 0.8000, 0.9632, 0.9637, 0.9324, 0.9933, 0.8349, 0.9370, 0.7613,
        0.9862, 0.9485], device='cuda:0'),
 tensor(0.9000, device='cuda:0'): tensor([0.9803, 0.9777, 0.9964, 0.9158, 0.8759, 0.9938, 0.9705, 1.0000, 0.9198,
        0.9082, 0.8047, 0.9723, 0.9684, 0.9412, 0.9982, 0.8350, 0.9512, 0.7847,
        0.9862, 0.9526], device='cuda:0'),
 tensor(0.9250, device='cuda:0'): tensor([0.9866, 0.9827, 0.9963, 0.9382, 0.9062, 1.0000, 0.9802, 1.0000, 0.9353,
        0.9140, 0.8000, 0.9737, 0.9677, 0.9596, 0.9990, 0.8495, 0.9583, 0.7970,
        0.9860, 0.9617], device='cuda:0'),
 tensor(0.9500, device='cuda:0'): tensor([0.9896, 0.9819, 0.9962, 0.9699, 0.9204, 1.0000, 0.9874, 1.0000, 0.9661,
        0.9091, 0.8218, 0.9762, 0.9771, 0.9730, 0.9988, 0.8861, 0.9658, 0.8362,
        0.9902, 0.9661], device='cuda:0'),
 tensor(0.9750, device='cuda:0'): tensor([0.9963, 0.9935, 0.9959, 0.9740, 0.9600, 1.0000, 0.9950, 1.0000, 0.9765,
        0.9359, 0.8571, 0.9843, 0.9871, 0.9880, 0.9984, 0.9265, 0.9811, 0.8571,
        1.0000, 0.9691], device='cuda:0')}
Best AP: 0.8821460504347555
Best Accuracy: 0.9755366649493389
Best weights saved to weights/five_crop_weights.pth
Training loss array saved to saves/five_crop_train_loss.npy
Validation loss array saved to saves/five_crop_val_loss.npy
Filenames saved to saves/five_crop_fnames.npy
Model outputs saved to saves/five_crop_outputs.pth
Labels saved to saves/five_crop_labels.pth
Accuracy saved to saves/five_crop_acc.npy
Average precision saved to saves/five_crop_ap.npy
Tail accuracy saved to saves/five_crop_tailacc.pth
