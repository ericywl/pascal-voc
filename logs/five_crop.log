Epoch 0
======================
TRAIN:
[0/5717 (0%)] Loss: 0.387677
[1600/5717 (28%)] Loss: 0.080992
[3200/5717 (56%)] Loss: 0.058526
[4800/5717 (84%)] Loss: 0.044039
[5717/5717 (100%)] Loss: 0.052321
Average training loss: 0.07128958514259828
VAL:
[0/5823 (0%)] Loss: 0.024938
[1600/5823 (27%)] Loss: 0.065519
[3200/5823 (55%)] Loss: 0.041310
[4800/5823 (82%)] Loss: 0.030597
[5823/5823 (100%)] Loss: 0.049754
Average validation loss: 0.04422767543755881
AP: 0.7764290145221833
Accuracy: 0.5528679490089417

Epoch 1
======================
TRAIN:
[0/5717 (0%)] Loss: 0.055117
[1600/5717 (28%)] Loss: 0.051628
[3200/5717 (56%)] Loss: 0.036511
[4800/5717 (84%)] Loss: 0.044082
[5717/5717 (100%)] Loss: 0.053420
Average training loss: 0.046568955204912
VAL:
[0/5823 (0%)] Loss: 0.031621
[1600/5823 (27%)] Loss: 0.025476
[3200/5823 (55%)] Loss: 0.028410
[4800/5823 (82%)] Loss: 0.051280
[5823/5823 (100%)] Loss: 0.038563
Average validation loss: 0.03700259770266712
AP: 0.8321275333271749
Accuracy: 0.6817147731781006

Epoch 2
======================
TRAIN:
[0/5717 (0%)] Loss: 0.041233
[1600/5717 (28%)] Loss: 0.039875
[3200/5717 (56%)] Loss: 0.032451
[4800/5717 (84%)] Loss: 0.027217
[5717/5717 (100%)] Loss: 0.018679
Average training loss: 0.03873133040912501
VAL:
[0/5823 (0%)] Loss: 0.068534
[1600/5823 (27%)] Loss: 0.047884
[3200/5823 (55%)] Loss: 0.019534
[4800/5823 (82%)] Loss: 0.036686
[5823/5823 (100%)] Loss: 0.015852
Average validation loss: 0.0348215205748412
AP: 0.8509524868436541
Accuracy: 0.7357202768325806

Epoch 3
======================
TRAIN:
[0/5717 (0%)] Loss: 0.024599
[1600/5717 (28%)] Loss: 0.048688
[3200/5717 (56%)] Loss: 0.034713
[4800/5717 (84%)] Loss: 0.057748
[5717/5717 (100%)] Loss: 0.015466
Average training loss: 0.033833503456121974
VAL:
[0/5823 (0%)] Loss: 0.021329
[1600/5823 (27%)] Loss: 0.057443
[3200/5823 (55%)] Loss: 0.048366
[4800/5823 (82%)] Loss: 0.040624
[5823/5823 (100%)] Loss: 0.018332
Average validation loss: 0.03207752846467953
AP: 0.8632175094745614
Accuracy: 0.7480541467666626

Epoch 4
======================
TRAIN:
[0/5717 (0%)] Loss: 0.023131
[1600/5717 (28%)] Loss: 0.024770
[3200/5717 (56%)] Loss: 0.035546
[4800/5717 (84%)] Loss: 0.031896
[5717/5717 (100%)] Loss: 0.019963
Average training loss: 0.03040867478332736
VAL:
[0/5823 (0%)] Loss: 0.024787
[1600/5823 (27%)] Loss: 0.016154
[3200/5823 (55%)] Loss: 0.019100
[4800/5823 (82%)] Loss: 0.016892
[5823/5823 (100%)] Loss: 0.012521
Average validation loss: 0.031472251509382786
AP: 0.8674513417578735
Accuracy: 0.7369177341461182

Epoch 5
======================
TRAIN:
[0/5717 (0%)] Loss: 0.041158
[1600/5717 (28%)] Loss: 0.024703
[3200/5717 (56%)] Loss: 0.024449
[4800/5717 (84%)] Loss: 0.030693
[5717/5717 (100%)] Loss: 0.049012
Average training loss: 0.027000648306252865
VAL:
[0/5823 (0%)] Loss: 0.009549
[1600/5823 (27%)] Loss: 0.060698
[3200/5823 (55%)] Loss: 0.017504
[4800/5823 (82%)] Loss: 0.035992
[5823/5823 (100%)] Loss: 0.025766
Average validation loss: 0.031488278695218426
AP: 0.8725759796705842
Accuracy: 0.7692492008209229

Epoch 6
======================
TRAIN:
[0/5717 (0%)] Loss: 0.017381
[1600/5717 (28%)] Loss: 0.020167
[3200/5717 (56%)] Loss: 0.031571
[4800/5717 (84%)] Loss: 0.018273
[5717/5717 (100%)] Loss: 0.041971
Average training loss: 0.02441759589616652
VAL:
[0/5823 (0%)] Loss: 0.042239
[1600/5823 (27%)] Loss: 0.020892
[3200/5823 (55%)] Loss: 0.034480
[4800/5823 (82%)] Loss: 0.039545
[5823/5823 (100%)] Loss: 0.013075
Average validation loss: 0.030367035509898214
AP: 0.8756995814596605
Accuracy: 0.755837619304657

Epoch 7
======================
TRAIN:
[0/5717 (0%)] Loss: 0.009940
[1600/5717 (28%)] Loss: 0.011779
[3200/5717 (56%)] Loss: 0.012387
[4800/5717 (84%)] Loss: 0.021539
[5717/5717 (100%)] Loss: 0.029589
Average training loss: 0.022012668152476524
VAL:
[0/5823 (0%)] Loss: 0.034234
[1600/5823 (27%)] Loss: 0.031969
[3200/5823 (55%)] Loss: 0.059901
[4800/5823 (82%)] Loss: 0.039296
[5823/5823 (100%)] Loss: 0.028507
Average validation loss: 0.02997802457756844
AP: 0.8779769523280925
Accuracy: 0.7704466581344604

Epoch 8
======================
TRAIN:
[0/5717 (0%)] Loss: 0.012444
[1600/5717 (28%)] Loss: 0.022945
[3200/5717 (56%)] Loss: 0.030049
[4800/5717 (84%)] Loss: 0.015513
[5717/5717 (100%)] Loss: 0.013676
Average training loss: 0.019031075997134814
VAL:
[0/5823 (0%)] Loss: 0.022290
[1600/5823 (27%)] Loss: 0.043132
[3200/5823 (55%)] Loss: 0.020562
[4800/5823 (82%)] Loss: 0.072669
[5823/5823 (100%)] Loss: 0.021457
Average validation loss: 0.03061719418370298
AP: 0.8781195501460451
Accuracy: 0.7696084380149841

Epoch 9
======================
TRAIN:
[0/5717 (0%)] Loss: 0.011707
[1600/5717 (28%)] Loss: 0.009692
[3200/5717 (56%)] Loss: 0.017514
[4800/5717 (84%)] Loss: 0.011047
[5717/5717 (100%)] Loss: 0.060381
Average training loss: 0.017325991261880714
VAL:
[0/5823 (0%)] Loss: 0.050597
[1600/5823 (27%)] Loss: 0.030146
[3200/5823 (55%)] Loss: 0.025120
[4800/5823 (82%)] Loss: 0.004557
[5823/5823 (100%)] Loss: 0.013421
Average validation loss: 0.030083917755861306
AP: 0.8807842962810096
Accuracy: 0.7698479294776917

Epoch 10
======================
TRAIN:
[0/5717 (0%)] Loss: 0.013212
[1600/5717 (28%)] Loss: 0.023531
[3200/5717 (56%)] Loss: 0.025208
[4800/5717 (84%)] Loss: 0.009832
[5717/5717 (100%)] Loss: 0.069602
Average training loss: 0.015041201874952425
VAL:
[0/5823 (0%)] Loss: 0.023679
[1600/5823 (27%)] Loss: 0.027785
[3200/5823 (55%)] Loss: 0.022642
[4800/5823 (82%)] Loss: 0.025345
[5823/5823 (100%)] Loss: 0.014531
Average validation loss: 0.02979968746904678
AP: 0.8807034417250791
Accuracy: 0.7715243697166443

Epoch 11
======================
TRAIN:
[0/5717 (0%)] Loss: 0.007736
[1600/5717 (28%)] Loss: 0.010208
[3200/5717 (56%)] Loss: 0.011738
[4800/5717 (84%)] Loss: 0.006891
[5717/5717 (100%)] Loss: 0.016051
Average training loss: 0.014502264918446854
VAL:
[0/5823 (0%)] Loss: 0.043109
[1600/5823 (27%)] Loss: 0.013932
[3200/5823 (55%)] Loss: 0.021544
[4800/5823 (82%)] Loss: 0.013335
[5823/5823 (100%)] Loss: 0.033901
Average validation loss: 0.029710768269768987
AP: 0.8812344822436031
Accuracy: 0.7570350766181946

Epoch 12
======================
TRAIN:
[0/5717 (0%)] Loss: 0.008966
[1600/5717 (28%)] Loss: 0.013400
[3200/5717 (56%)] Loss: 0.007386
[4800/5717 (84%)] Loss: 0.007464
[5717/5717 (100%)] Loss: 0.011456
Average training loss: 0.014382335821075455
VAL:
[0/5823 (0%)] Loss: 0.034438
[1600/5823 (27%)] Loss: 0.035864
[3200/5823 (55%)] Loss: 0.029773
[4800/5823 (82%)] Loss: 0.032063
[5823/5823 (100%)] Loss: 0.051658
Average validation loss: 0.03005109316682837
AP: 0.881322760089379
Accuracy: 0.7818225622177124

Epoch 13
======================
TRAIN:
[0/5717 (0%)] Loss: 0.016777
[1600/5717 (28%)] Loss: 0.007702
[3200/5717 (56%)] Loss: 0.011350
[4800/5717 (84%)] Loss: 0.016281
[5717/5717 (100%)] Loss: 0.016418
Average training loss: 0.014040542223940154
VAL:
[0/5823 (0%)] Loss: 0.013673
[1600/5823 (27%)] Loss: 0.081551
[3200/5823 (55%)] Loss: 0.021982
[4800/5823 (82%)] Loss: 0.055377
[5823/5823 (100%)] Loss: 0.008076
Average validation loss: 0.02943998763266091
AP: 0.8818179396825093
Accuracy: 0.7660160660743713

Epoch 14
======================
TRAIN:
[0/5717 (0%)] Loss: 0.031293
[1600/5717 (28%)] Loss: 0.006843
[3200/5717 (56%)] Loss: 0.011733
[4800/5717 (84%)] Loss: 0.007071
[5717/5717 (100%)] Loss: 0.004263
Average training loss: 0.014045114014167468
VAL:
[0/5823 (0%)] Loss: 0.006312
[1600/5823 (27%)] Loss: 0.026227
[3200/5823 (55%)] Loss: 0.028187
[4800/5823 (82%)] Loss: 0.031441
[5823/5823 (100%)] Loss: 0.039280
Average validation loss: 0.029772850788124212
AP: 0.8810245888037409
Accuracy: 0.7760747075080872

Epoch 15
======================
TRAIN:
[0/5717 (0%)] Loss: 0.010234
[1600/5717 (28%)] Loss: 0.010664
[3200/5717 (56%)] Loss: 0.004808
[4800/5717 (84%)] Loss: 0.019080
[5717/5717 (100%)] Loss: 0.025858
Average training loss: 0.013792735917194114
VAL:
[0/5823 (0%)] Loss: 0.057211
[1600/5823 (27%)] Loss: 0.026307
[3200/5823 (55%)] Loss: 0.048026
[4800/5823 (82%)] Loss: 0.017539
[5823/5823 (100%)] Loss: 0.068242
Average validation loss: 0.030060242145107344
AP: 0.8818871398434848
Accuracy: 0.7687702178955078

Epoch 16
======================
TRAIN:
[0/5717 (0%)] Loss: 0.012023
[1600/5717 (28%)] Loss: 0.008277
[3200/5717 (56%)] Loss: 0.012604
[4800/5717 (84%)] Loss: 0.005903
[5717/5717 (100%)] Loss: 0.029433
Average training loss: 0.01355769077635051
VAL:
[0/5823 (0%)] Loss: 0.019727
[1600/5823 (27%)] Loss: 0.036976
[3200/5823 (55%)] Loss: 0.028904
[4800/5823 (82%)] Loss: 0.012978
[5823/5823 (100%)] Loss: 0.027987
Average validation loss: 0.029471970954845956
AP: 0.8818163418206753
Accuracy: 0.7619446516036987

Epoch 17
======================
TRAIN:
[0/5717 (0%)] Loss: 0.015131
[1600/5717 (28%)] Loss: 0.009786
[3200/5717 (56%)] Loss: 0.009307
[4800/5717 (84%)] Loss: 0.019359
[5717/5717 (100%)] Loss: 0.017901
Average training loss: 0.013266301969509129
VAL:
[0/5823 (0%)] Loss: 0.039454
[1600/5823 (27%)] Loss: 0.029063
[3200/5823 (55%)] Loss: 0.032941
[4800/5823 (82%)] Loss: 0.009992
[5823/5823 (100%)] Loss: 0.005963
Average validation loss: 0.029540476443279267
AP: 0.8816795303480885
Accuracy: 0.768650472164154

Epoch 18
======================
TRAIN:
[0/5717 (0%)] Loss: 0.023742
[1600/5717 (28%)] Loss: 0.009351
[3200/5717 (56%)] Loss: 0.005010
[4800/5717 (84%)] Loss: 0.025934
[5717/5717 (100%)] Loss: 0.013081
Average training loss: 0.012936868933452802
VAL:
[0/5823 (0%)] Loss: 0.018146
[1600/5823 (27%)] Loss: 0.028441
[3200/5823 (55%)] Loss: 0.014080
[4800/5823 (82%)] Loss: 0.020896
[5823/5823 (100%)] Loss: 0.011978
Average validation loss: 0.030149304697860625
AP: 0.8818897899242533
Accuracy: 0.7783498764038086

Epoch 19
======================
TRAIN:
[0/5717 (0%)] Loss: 0.009542
[1600/5717 (28%)] Loss: 0.013407
[3200/5717 (56%)] Loss: 0.010900
[4800/5717 (84%)] Loss: 0.013583
[5717/5717 (100%)] Loss: 0.012089
Average training loss: 0.012844942172116541
VAL:
[0/5823 (0%)] Loss: 0.013014
[1600/5823 (27%)] Loss: 0.051546
[3200/5823 (55%)] Loss: 0.031196
[4800/5823 (82%)] Loss: 0.031072
[5823/5823 (100%)] Loss: 0.034197
Average validation loss: 0.02988624250213104
AP: 0.8824240302501526
Accuracy: 0.7682912349700928

Epoch 20
======================
TRAIN:
[0/5717 (0%)] Loss: 0.010099
[1600/5717 (28%)] Loss: 0.011296
[3200/5717 (56%)] Loss: 0.009363
[4800/5717 (84%)] Loss: 0.006320
[5717/5717 (100%)] Loss: 0.014562
Average training loss: 0.01279791070708445
VAL:
[0/5823 (0%)] Loss: 0.078813
[1600/5823 (27%)] Loss: 0.030167
[3200/5823 (55%)] Loss: 0.031674
[4800/5823 (82%)] Loss: 0.030653
[5823/5823 (100%)] Loss: 0.031544
Average validation loss: 0.030216606906653575
AP: 0.8821138487450714
Accuracy: 0.7819423079490662

Epoch 21
======================
TRAIN:
[0/5717 (0%)] Loss: 0.007710
[1600/5717 (28%)] Loss: 0.033597
[3200/5717 (56%)] Loss: 0.009248
[4800/5717 (84%)] Loss: 0.014249
[5717/5717 (100%)] Loss: 0.011029
Average training loss: 0.012684866995387874
VAL:
[0/5823 (0%)] Loss: 0.013600
[1600/5823 (27%)] Loss: 0.042201
[3200/5823 (55%)] Loss: 0.023973
[4800/5823 (82%)] Loss: 0.026427
[5823/5823 (100%)] Loss: 0.028850
Average validation loss: 0.02954916620005311
AP: 0.8821878729206961
Accuracy: 0.7614656686782837

Epoch 22
======================
TRAIN:
[0/5717 (0%)] Loss: 0.023223
[1600/5717 (28%)] Loss: 0.008046
[3200/5717 (56%)] Loss: 0.005916
[4800/5717 (84%)] Loss: 0.009402
[5717/5717 (100%)] Loss: 0.019094
Average training loss: 0.012941107517303704
VAL:
[0/5823 (0%)] Loss: 0.045894
[1600/5823 (27%)] Loss: 0.008416
[3200/5823 (55%)] Loss: 0.026700
[4800/5823 (82%)] Loss: 0.022388
[5823/5823 (100%)] Loss: 0.003736
Average validation loss: 0.029935823015006423
AP: 0.8826588950638814
Accuracy: 0.78302001953125

Epoch 23
======================
TRAIN:
[0/5717 (0%)] Loss: 0.022889
[1600/5717 (28%)] Loss: 0.030840
[3200/5717 (56%)] Loss: 0.010532
[4800/5717 (84%)] Loss: 0.011081
[5717/5717 (100%)] Loss: 0.018762
Average training loss: 0.012971474128690633
VAL:
[0/5823 (0%)] Loss: 0.014766
[1600/5823 (27%)] Loss: 0.008736
[3200/5823 (55%)] Loss: 0.027539
[4800/5823 (82%)] Loss: 0.018834
[5823/5823 (100%)] Loss: 0.034528
Average validation loss: 0.030276095730017175
AP: 0.8815939116653101
Accuracy: 0.7858939170837402

Epoch 24
======================
TRAIN:
[0/5717 (0%)] Loss: 0.006979
[1600/5717 (28%)] Loss: 0.011127
[3200/5717 (56%)] Loss: 0.011379
[4800/5717 (84%)] Loss: 0.013391
[5717/5717 (100%)] Loss: 0.008941
Average training loss: 0.012830014036759943
VAL:
[0/5823 (0%)] Loss: 0.031137
[1600/5823 (27%)] Loss: 0.031125
[3200/5823 (55%)] Loss: 0.022876
[4800/5823 (82%)] Loss: 0.028255
[5823/5823 (100%)] Loss: 0.026893
Average validation loss: 0.029930717409984976
AP: 0.8815481513528118
Accuracy: 0.7703269124031067

Epoch 25
======================
TRAIN:
[0/5717 (0%)] Loss: 0.006986
[1600/5717 (28%)] Loss: 0.008679
[3200/5717 (56%)] Loss: 0.022345
[4800/5717 (84%)] Loss: 0.012112
[5717/5717 (100%)] Loss: 0.015600
Average training loss: 0.012830936291313672
VAL:
[0/5823 (0%)] Loss: 0.041743
[1600/5823 (27%)] Loss: 0.039085
[3200/5823 (55%)] Loss: 0.022402
[4800/5823 (82%)] Loss: 0.031048
[5823/5823 (100%)] Loss: 0.081703
Average validation loss: 0.030394447513262403
AP: 0.881615243303743
Accuracy: 0.789486289024353

Epoch 26
======================
TRAIN:
[0/5717 (0%)] Loss: 0.021452
[1600/5717 (28%)] Loss: 0.009148
[3200/5717 (56%)] Loss: 0.009440
[4800/5717 (84%)] Loss: 0.014502
[5717/5717 (100%)] Loss: 0.035530
Average training loss: 0.012466866649049042
VAL:
[0/5823 (0%)] Loss: 0.027029
[1600/5823 (27%)] Loss: 0.034751
[3200/5823 (55%)] Loss: 0.032623
[4800/5823 (82%)] Loss: 0.023753
[5823/5823 (100%)] Loss: 0.039442
Average validation loss: 0.0299189510965684
AP: 0.8816506991121772
Accuracy: 0.7555981278419495

Epoch 27
======================
TRAIN:
[0/5717 (0%)] Loss: 0.012207
[1600/5717 (28%)] Loss: 0.007382
[3200/5717 (56%)] Loss: 0.028990
[4800/5717 (84%)] Loss: 0.013948
[5717/5717 (100%)] Loss: 0.039125
Average training loss: 0.012525228928396855
VAL:
[0/5823 (0%)] Loss: 0.016636
[1600/5823 (27%)] Loss: 0.008054
[3200/5823 (55%)] Loss: 0.021226
[4800/5823 (82%)] Loss: 0.030874
[5823/5823 (100%)] Loss: 0.048505
Average validation loss: 0.029908970022666174
AP: 0.882172023592503
Accuracy: 0.76469886302948

Epoch 28
======================
TRAIN:
[0/5717 (0%)] Loss: 0.012001
[1600/5717 (28%)] Loss: 0.025630
[3200/5717 (56%)] Loss: 0.006949
[4800/5717 (84%)] Loss: 0.008254
[5717/5717 (100%)] Loss: 0.006639
Average training loss: 0.012624044178731062
VAL:
[0/5823 (0%)] Loss: 0.010486
[1600/5823 (27%)] Loss: 0.035587
[3200/5823 (55%)] Loss: 0.027290
[4800/5823 (82%)] Loss: 0.014843
[5823/5823 (100%)] Loss: 0.075012
Average validation loss: 0.02977307321814626
AP: 0.8815612736995516
Accuracy: 0.774158775806427

Epoch 29
======================
TRAIN:
[0/5717 (0%)] Loss: 0.011487
[1600/5717 (28%)] Loss: 0.010412
[3200/5717 (56%)] Loss: 0.009994
[4800/5717 (84%)] Loss: 0.013264
[5717/5717 (100%)] Loss: 0.029360
Average training loss: 0.012520788272295694
VAL:
[0/5823 (0%)] Loss: 0.057977
[1600/5823 (27%)] Loss: 0.021728
[3200/5823 (55%)] Loss: 0.028594
[4800/5823 (82%)] Loss: 0.027415
[5823/5823 (100%)] Loss: 0.023808
Average validation loss: 0.029984414106705687
AP: 0.8817773915119174
Accuracy: 0.7735600471496582

Epoch 30
======================
TRAIN:
[0/5717 (0%)] Loss: 0.012121
[1600/5717 (28%)] Loss: 0.007766
[3200/5717 (56%)] Loss: 0.008186
[4800/5717 (84%)] Loss: 0.007143
[5717/5717 (100%)] Loss: 0.028329
Average training loss: 0.012653388458766512
VAL:
[0/5823 (0%)] Loss: 0.012110
[1600/5823 (27%)] Loss: 0.018764
[3200/5823 (55%)] Loss: 0.060494
[4800/5823 (82%)] Loss: 0.032127
[5823/5823 (100%)] Loss: 0.042999
Average validation loss: 0.030252637840221523
AP: 0.882330150725926
Accuracy: 0.7802658081054688

Epoch 31
======================
TRAIN:
[0/5717 (0%)] Loss: 0.007773
[1600/5717 (28%)] Loss: 0.004198
[3200/5717 (56%)] Loss: 0.011815
[4800/5717 (84%)] Loss: 0.009180
[5717/5717 (100%)] Loss: 0.026121
Average training loss: 0.012443315318192948
VAL:
[0/5823 (0%)] Loss: 0.028683
[1600/5823 (27%)] Loss: 0.023769
[3200/5823 (55%)] Loss: 0.046734
[4800/5823 (82%)] Loss: 0.010528
[5823/5823 (100%)] Loss: 0.009617
Average validation loss: 0.02976335229283035
AP: 0.8817175379102803
Accuracy: 0.7696084380149841

Epoch 32
======================
TRAIN:
[0/5717 (0%)] Loss: 0.008695
[1600/5717 (28%)] Loss: 0.008131
[3200/5717 (56%)] Loss: 0.021292
[4800/5717 (84%)] Loss: 0.010074
[5717/5717 (100%)] Loss: 0.010196
Average training loss: 0.0126049955300596
VAL:
[0/5823 (0%)] Loss: 0.052961
[1600/5823 (27%)] Loss: 0.017823
[3200/5823 (55%)] Loss: 0.054901
[4800/5823 (82%)] Loss: 0.017602
[5823/5823 (100%)] Loss: 0.039423
Average validation loss: 0.030147994811209125
AP: 0.8821730247325525
Accuracy: 0.7799065709114075

Epoch 33
======================
TRAIN:
[0/5717 (0%)] Loss: 0.009922
[1600/5717 (28%)] Loss: 0.018296
[3200/5717 (56%)] Loss: 0.020028
[4800/5717 (84%)] Loss: 0.015766
[5717/5717 (100%)] Loss: 0.009099
Average training loss: 0.012643241427083323
VAL:
[0/5823 (0%)] Loss: 0.042057
[1600/5823 (27%)] Loss: 0.064714
[3200/5823 (55%)] Loss: 0.003124
[4800/5823 (82%)] Loss: 0.022848
[5823/5823 (100%)] Loss: 0.016843
Average validation loss: 0.03037495887262624
AP: 0.8814521952759823
Accuracy: 0.7820620536804199

Epoch 34
======================
TRAIN:
[0/5717 (0%)] Loss: 0.007541
[1600/5717 (28%)] Loss: 0.006969
[3200/5717 (56%)] Loss: 0.008274
[4800/5717 (84%)] Loss: 0.006893
[5717/5717 (100%)] Loss: 0.081601
Average training loss: 0.012843177161159946
VAL:
[0/5823 (0%)] Loss: 0.027969
[1600/5823 (27%)] Loss: 0.018212
[3200/5823 (55%)] Loss: 0.025907
[4800/5823 (82%)] Loss: 0.004505
[5823/5823 (100%)] Loss: 0.040920
Average validation loss: 0.029679660030364336
AP: 0.8819317926986279
Accuracy: 0.7639803886413574

Epoch 35
======================
TRAIN:
[0/5717 (0%)] Loss: 0.005008
[1600/5717 (28%)] Loss: 0.005226
[3200/5717 (56%)] Loss: 0.010323
[4800/5717 (84%)] Loss: 0.011985
[5717/5717 (100%)] Loss: 0.028783
Average training loss: 0.012783360095056413
VAL:
[0/5823 (0%)] Loss: 0.023929
[1600/5823 (27%)] Loss: 0.004382
[3200/5823 (55%)] Loss: 0.013226
[4800/5823 (82%)] Loss: 0.062490
[5823/5823 (100%)] Loss: 0.038666
Average validation loss: 0.03009857290589435
AP: 0.8814269060566189
Accuracy: 0.7664950489997864

Epoch 36
======================
TRAIN:
[0/5717 (0%)] Loss: 0.019576
[1600/5717 (28%)] Loss: 0.010434
[3200/5717 (56%)] Loss: 0.015830
[4800/5717 (84%)] Loss: 0.023185
[5717/5717 (100%)] Loss: 0.010661
Average training loss: 0.01265088856819418
VAL:
[0/5823 (0%)] Loss: 0.007634
[1600/5823 (27%)] Loss: 0.011580
[3200/5823 (55%)] Loss: 0.028173
[4800/5823 (82%)] Loss: 0.032157
[5823/5823 (100%)] Loss: 0.017369
Average validation loss: 0.02999844454749549
AP: 0.8821720038572625
Accuracy: 0.7729613184928894

Epoch 37
======================
TRAIN:
[0/5717 (0%)] Loss: 0.007161
[1600/5717 (28%)] Loss: 0.051235
[3200/5717 (56%)] Loss: 0.008240
[4800/5717 (84%)] Loss: 0.011971
[5717/5717 (100%)] Loss: 0.011402
Average training loss: 0.012428208771389681
VAL:
[0/5823 (0%)] Loss: 0.011160
[1600/5823 (27%)] Loss: 0.018693
[3200/5823 (55%)] Loss: 0.044462
[4800/5823 (82%)] Loss: 0.021943
[5823/5823 (100%)] Loss: 0.016645
Average validation loss: 0.030218781163157373
AP: 0.8814849068816368
Accuracy: 0.7608669400215149

Epoch 38
======================
TRAIN:
[0/5717 (0%)] Loss: 0.030161
[1600/5717 (28%)] Loss: 0.012714
[3200/5717 (56%)] Loss: 0.012467
[4800/5717 (84%)] Loss: 0.008436
[5717/5717 (100%)] Loss: 0.012173
Average training loss: 0.012588904130474463
VAL:
[0/5823 (0%)] Loss: 0.017142
[1600/5823 (27%)] Loss: 0.042048
[3200/5823 (55%)] Loss: 0.020608
[4800/5823 (82%)] Loss: 0.042670
[5823/5823 (100%)] Loss: 0.068293
Average validation loss: 0.02993356472950756
AP: 0.8821737315821028
Accuracy: 0.7751167416572571

Epoch 39
======================
TRAIN:
[0/5717 (0%)] Loss: 0.005075
[1600/5717 (28%)] Loss: 0.009579
[3200/5717 (56%)] Loss: 0.017662
[4800/5717 (84%)] Loss: 0.017777
[5717/5717 (100%)] Loss: 0.005256
Average training loss: 0.01265121273227505
VAL:
[0/5823 (0%)] Loss: 0.026626
[1600/5823 (27%)] Loss: 0.013078
[3200/5823 (55%)] Loss: 0.009146
[4800/5823 (82%)] Loss: 0.033885
[5823/5823 (100%)] Loss: 0.036216
Average validation loss: 0.02976514711965817
AP: 0.8821233281295934
Accuracy: 0.7709256410598755

Measuring performance using best weights...
[0/5823 (0%)]
[1600/5823 (27%)]
[3200/5823 (55%)]
[4800/5823 (82%)]
[5823/5823 (100%)]
Tailacc:
{tensor(0.5000, device='cuda:0'): tensor([0.9337, 0.8802, 0.9700, 0.8326, 0.7044, 0.9516, 0.8647, 0.9570, 0.7677,
        0.7742, 0.6977, 0.8937, 0.8816, 0.8308, 0.9382, 0.6482, 0.8269, 0.6534,
        0.9266, 0.8686], device='cuda:0'),
 tensor(0.5250, device='cuda:0'): tensor([0.9444, 0.8866, 0.9758, 0.8390, 0.7052, 0.9568, 0.8702, 0.9568, 0.7760,
        0.7843, 0.7081, 0.8979, 0.8884, 0.8471, 0.9471, 0.6702, 0.8377, 0.6626,
        0.9302, 0.8874], device='cuda:0'),
 tensor(0.5500, device='cuda:0'): tensor([0.9443, 0.8898, 0.9758, 0.8455, 0.7126, 0.9670, 0.8750, 0.9607, 0.7811,
        0.7987, 0.7067, 0.9069, 0.8921, 0.8465, 0.9530, 0.6902, 0.8477, 0.6639,
        0.9368, 0.8904], device='cuda:0'),
 tensor(0.5750, device='cuda:0'): tensor([0.9467, 0.8918, 0.9787, 0.8590, 0.7233, 0.9724, 0.8875, 0.9642, 0.7889,
        0.8027, 0.7024, 0.9101, 0.8958, 0.8577, 0.9630, 0.7039, 0.8533, 0.6781,
        0.9442, 0.8929], device='cuda:0'),
 tensor(0.6000, device='cuda:0'): tensor([0.9524, 0.8952, 0.9784, 0.8622, 0.7309, 0.9724, 0.8908, 0.9681, 0.7839,
        0.8028, 0.7059, 0.9123, 0.8958, 0.8571, 0.9698, 0.7184, 0.8649, 0.6756,
        0.9516, 0.9000], device='cuda:0'),
 tensor(0.6250, device='cuda:0'): tensor([0.9552, 0.8978, 0.9814, 0.8655, 0.7490, 0.9775, 0.8977, 0.9741, 0.7976,
        0.8129, 0.7157, 0.9192, 0.8987, 0.8601, 0.9742, 0.7193, 0.8767, 0.6864,
        0.9551, 0.9124], device='cuda:0'),
 tensor(0.6500, device='cuda:0'): tensor([0.9580, 0.9058, 0.9812, 0.8688, 0.7598, 0.9775, 0.9021, 0.9740, 0.8115,
        0.8148, 0.7240, 0.9268, 0.9099, 0.8686, 0.9776, 0.7329, 0.8828, 0.7048,
        0.9630, 0.9167], device='cuda:0'),
 tensor(0.6750, device='cuda:0'): tensor([0.9607, 0.9050, 0.9810, 0.8688, 0.7661, 0.9774, 0.9197, 0.9802, 0.8146,
        0.8258, 0.7419, 0.9310, 0.9217, 0.8755, 0.9791, 0.7419, 0.8889, 0.7143,
        0.9628, 0.9167], device='cuda:0'),
 tensor(0.7000, device='cuda:0'): tensor([0.9607, 0.9087, 0.9839, 0.8704, 0.7826, 0.9771, 0.9288, 0.9822, 0.8112,
        0.8372, 0.7598, 0.9354, 0.9214, 0.8788, 0.9819, 0.7467, 0.9014, 0.7164,
        0.9625, 0.9206], device='cuda:0'),
 tensor(0.7250, device='cuda:0'): tensor([0.9636, 0.9163, 0.9839, 0.8698, 0.7960, 0.9828, 0.9388, 0.9908, 0.8155,
        0.8333, 0.7598, 0.9429, 0.9207, 0.8865, 0.9828, 0.7448, 0.9007, 0.7200,
        0.9623, 0.9202], device='cuda:0'),
 tensor(0.7500, device='cuda:0'): tensor([0.9694, 0.9289, 0.9870, 0.8821, 0.8030, 0.9827, 0.9408, 0.9930, 0.8392,
        0.8374, 0.7644, 0.9442, 0.9193, 0.8855, 0.9858, 0.7664, 0.9065, 0.7202,
        0.9622, 0.9190], device='cuda:0'),
 tensor(0.7750, device='cuda:0'): tensor([0.9752, 0.9507, 0.9900, 0.8863, 0.8010, 0.9827, 0.9480, 0.9929, 0.8734,
        0.8512, 0.7706, 0.9492, 0.9263, 0.8919, 0.9881, 0.7687, 0.9191, 0.7219,
        0.9700, 0.9363], device='cuda:0'),
 tensor(0.8000, device='cuda:0'): tensor([0.9748, 0.9598, 0.9933, 0.8947, 0.8000, 0.9882, 0.9533, 0.9952, 0.8899,
        0.8621, 0.7744, 0.9518, 0.9256, 0.8950, 0.9906, 0.7907, 0.9254, 0.7263,
        0.9740, 0.9406], device='cuda:0'),
 tensor(0.8250, device='cuda:0'): tensor([0.9748, 0.9643, 0.9932, 0.9024, 0.7955, 0.9880, 0.9579, 0.9976, 0.9048,
        0.8807, 0.7848, 0.9531, 0.9375, 0.9028, 0.9910, 0.8033, 0.9237, 0.7267,
        0.9737, 0.9450], device='cuda:0'),
 tensor(0.8500, device='cuda:0'): tensor([0.9807, 0.9628, 0.9931, 0.9100, 0.8133, 0.9880, 0.9664, 0.9975, 0.9040,
        0.8879, 0.7933, 0.9620, 0.9458, 0.9151, 0.9930, 0.8034, 0.9375, 0.7469,
        0.9776, 0.9439], device='cuda:0'),
 tensor(0.8750, device='cuda:0'): tensor([0.9804, 0.9672, 0.9965, 0.9184, 0.8333, 0.9880, 0.9679, 1.0000, 0.9050,
        0.9020, 0.7972, 0.9651, 0.9635, 0.9372, 0.9933, 0.8349, 0.9440, 0.7613,
        0.9817, 0.9482], device='cuda:0'),
 tensor(0.9000, device='cuda:0'): tensor([0.9803, 0.9777, 0.9964, 0.9251, 0.8824, 0.9938, 0.9704, 1.0000, 0.9202,
        0.9091, 0.8095, 0.9723, 0.9684, 0.9409, 0.9973, 0.8350, 0.9516, 0.7862,
        0.9862, 0.9521], device='cuda:0'),
 tensor(0.9250, device='cuda:0'): tensor([0.9865, 0.9827, 0.9963, 0.9382, 0.9070, 1.0000, 0.9764, 1.0000, 0.9362,
        0.9032, 0.8018, 0.9736, 0.9677, 0.9596, 0.9990, 0.8511, 0.9583, 0.8015,
        0.9860, 0.9615], device='cuda:0'),
 tensor(0.9500, device='cuda:0'): tensor([0.9896, 0.9819, 0.9962, 0.9701, 0.9211, 1.0000, 0.9916, 1.0000, 0.9661,
        0.9091, 0.8218, 0.9763, 0.9714, 0.9728, 0.9988, 0.8974, 0.9658, 0.8390,
        0.9902, 0.9663], device='cuda:0'),
 tensor(0.9750, device='cuda:0'): tensor([0.9963, 0.9935, 0.9959, 0.9740, 0.9600, 1.0000, 0.9951, 1.0000, 0.9767,
        0.9231, 0.8571, 0.9842, 0.9872, 0.9881, 0.9984, 0.9265, 0.9813, 0.8542,
        1.0000, 0.9691], device='cuda:0')}
Best AP: 0.8821233281295934
Best Accuracy: 0.7709256410598755
